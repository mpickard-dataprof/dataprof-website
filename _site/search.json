[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Education\nBrigham Young University | Provo, UT\nB.S. in Computer Engineering | 2002\nBrigham Young University | Provo, UT\nMBA in Operations and Information Systems | 2008\nUniversity of Arizona | Tucson, AZ\nPh.D. in Management Information Systems | 2012\n\n\nExperience\nNational Instruments\nApplications Engineer | 2002 - 2004\nSoftware Engineer / Project Manager | 2004 - 2006\nRaytheon Missile Systems\nTechnical Instructor | 2010\nSandia National Labs\nFaculty Summer Intern - Data Analytics | 2017\nUniversity of New Mexico\nAssistant Professor of AIS and Analytics | 2012-2018\nNorthern Illinois University\nAssociate Professor of Data and Analytics | 2018-present"
  },
  {
    "objectID": "blog/dataprep/excel_conditional_aggregation/excel_conditional_aggregation.html",
    "href": "blog/dataprep/excel_conditional_aggregation/excel_conditional_aggregation.html",
    "title": "Excel Conditional Aggregation Functions (COUNTIFS, SUMIFS, AVERAGEIFS)",
    "section": "",
    "text": "Data aggregation is the process of combining multiple data points into a single number. It’s synonymous with summarization. In this post, we’ll review how to use aggregation functions in Excel – specifically, the conditional aggregation functions (e.g., COUNTIFS(), SUMIFS(), and AVERAGEIFS())."
  },
  {
    "objectID": "blog/dataprep/excel_conditional_aggregation/excel_conditional_aggregation.html#example-of-countifs",
    "href": "blog/dataprep/excel_conditional_aggregation/excel_conditional_aggregation.html#example-of-countifs",
    "title": "Excel Conditional Aggregation Functions (COUNTIFS, SUMIFS, AVERAGEIFS)",
    "section": "Example of COUNTIFS()",
    "text": "Example of COUNTIFS()\nThe COUNT function family is the simplest. We’ll demonstrate an example here.\n\n\n\nExample of the COUNTIFS Excel function\n\n\nNotice the formula in G1, takes pairs of arguments – criteria_range and criteria. Here we count only rows that meet two conditions:\n\nProduct = “Pants” – B2:B10 is the criteria_range1, in other words, that’s the range of cells we are going to check to see if they are equal to “Pants” (which is the criteria).\nColor = “Tan” – C2:C10 is the range of color values to check (criteria_range2) and “Tan” is the criteria.\n\nSo we only include products where the Color is “Tan” (and the Product is “Pants”) in the count.\nThis video shows more details."
  },
  {
    "objectID": "blog/dataprep/inner_join/inner_join.html",
    "href": "blog/dataprep/inner_join/inner_join.html",
    "title": "Inner Join",
    "section": "",
    "text": "An inner join keeps only rows from two tables that have matches. This Venn diagram illustrates which rows are included in an inner join."
  },
  {
    "objectID": "blog/dataprep/inner_join/inner_join.html#how-does-an-inner-join-work",
    "href": "blog/dataprep/inner_join/inner_join.html#how-does-an-inner-join-work",
    "title": "Inner Join",
    "section": "How does an inner join work?",
    "text": "How does an inner join work?\nAn inner join visits every row in the left table and then checks if there is a matching row in the right table. If there is, it combines the fields from the matching left and right row. If there is not a match, it drops the row. Thus only the “intersection” of rows from both tables is kept in the result."
  },
  {
    "objectID": "blog/dataprep/inner_join/inner_join.html#how-many-records-end-up-in-the-result-of-an-inner-join",
    "href": "blog/dataprep/inner_join/inner_join.html#how-many-records-end-up-in-the-result-of-an-inner-join",
    "title": "Inner Join",
    "section": "How many records end up in the result of an inner join?",
    "text": "How many records end up in the result of an inner join?\n\\(L =\\) # of records in the left table\n\\(R =\\) # of records in the right table\nThen the number of rows in the resulting inner join is \\(min(L,R)\\)\n\n\n\n\n\n\nLeft Table\n\n\n\n\n\n\n\nRight Table\n\n\n\n\n\n\n\n\n\nInner Joined Result\n\n\n\n\n\nNotice how the last row in the left table (id=5, name=\"Rowlf the Dog) and the last row in the right table (id=-8, role=\"frenzied monster drummer\", wage_per_hour=45.75) were dropped.\nThe Data School provides a nice animation of the row by row operations for an inner join."
  },
  {
    "objectID": "blog/dataprep/inner_join/inner_join.html#implementing-an-inner-join-in-different-tools",
    "href": "blog/dataprep/inner_join/inner_join.html#implementing-an-inner-join-in-different-tools",
    "title": "Inner Join",
    "section": "Implementing an inner join in different tools",
    "text": "Implementing an inner join in different tools\nHere is how you perform an inner join in R, Python, Power BI, and Excel.\n\nR\n\nlibrary(dplyr)\n\nemployees %>% \n  inner_join(positions, by = \"muppet_id\")\n\n# A tibble: 4 × 4\n  muppet_id names           role             wage_per_hour\n      <dbl> <chr>           <chr>                    <dbl>\n1         1 Kermit the Frog pragmatic leader          75  \n2         2 Miss Piggy      diva pig                  85  \n3         3 Fozzie the Bear stand-up comic            25.2\n4         4 Gonzo           stunt performer           54.5\n\n\n\n\nPython\n\n\n\n\nimport pandas as pd\n\npd.merge(employees, positions, how='inner')\n\n   muppet_id            names              role  wage_per_hour\n0        1.0  Kermit the Frog  pragmatic leader          75.00\n1        2.0       Miss Piggy          diva pig          85.00\n2        3.0  Fozzie the Bear    stand-up comic          25.25\n3        4.0            Gonzo   stunt performer          54.50\n\n\n\n\nPower BI\nIn Power BI, we invoke Power Query through the Home >> Transform data menu item. \n\n\nExcel\nIn native Excel, there is not a true inner join. The best we can do is mimic an inner join in two steps. First, find the set of intersecting values from the primary keys (ids) from both tables. We can use the MATCH() function to do this. Second, use that set of intersecting keys to merge in the columns together by using VLOOKUP() repeatedly.\n\n:::{.callout-note} You can invoke Power Query in Excel (through the Data >> Get Data menu item) to perform a true inner join. :::"
  },
  {
    "objectID": "blog/dataprep/left_join/left_join.html",
    "href": "blog/dataprep/left_join/left_join.html",
    "title": "Left Join",
    "section": "",
    "text": "A left join keeps all the rows from the left table and inserts NULLs on the right when there is not a matching row found in the right table.\nThis Venn diagram illustrates which rows are included in a left join.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA left join is the mirror of a right join."
  },
  {
    "objectID": "blog/dataprep/left_join/left_join.html#how-does-a-left-join-work",
    "href": "blog/dataprep/left_join/left_join.html#how-does-a-left-join-work",
    "title": "Left Join",
    "section": "How does a left join work?",
    "text": "How does a left join work?\nA left join visits every row in the left table and then checks if there is a matching row in the right table. If there is, it combines the matching left and right row. If there is not, it places nulls on the right side.\n\n\n\n\n\n\nLeft Table\n\n\n\n\n\n\n\nRight Table\n\n\n\n\n\n\n\n\n\nLeft Joined Result\n\n\n\n\n\nNotice how the last row (id=-5, name=\"Rowlf the Dog\") in the left table does not have a match in the right table. So, nulls are inserted into the right columns of the result.\nThe Data School provides a nice animation of the row by row operations for a left join."
  },
  {
    "objectID": "blog/dataprep/left_join/left_join.html#how-many-records-end-up-in-the-result-of-an-inner-join",
    "href": "blog/dataprep/left_join/left_join.html#how-many-records-end-up-in-the-result-of-an-inner-join",
    "title": "Left Join",
    "section": "How many records end up in the result of an inner join?",
    "text": "How many records end up in the result of an inner join?\n\\(L =\\) # of records in the left table\n\\(R =\\) # of records in the right table\nThe number of records in the final left join is \\(L\\)."
  },
  {
    "objectID": "blog/dataprep/left_join/left_join.html#implementing-a-left-join-in-different-tools",
    "href": "blog/dataprep/left_join/left_join.html#implementing-a-left-join-in-different-tools",
    "title": "Left Join",
    "section": "Implementing a left join in different tools",
    "text": "Implementing a left join in different tools\nHere is how you perform a left join in R, Python, Power BI, and Excel.\n\nR\n\nlibrary(dplyr)\n\nemployees %>% \n  left_join(positions, by = \"muppet_id\")\n\n# A tibble: 5 × 4\n  muppet_id names           role             wage_per_hour\n      <dbl> <chr>           <chr>                    <dbl>\n1         1 Kermit the Frog pragmatic leader          75  \n2         2 Miss Piggy      diva pig                  85  \n3         3 Fozzie the Bear stand-up comic            25.2\n4         4 Gonzo           stunt performer           54.5\n5         5 Rowlf the Dog   <NA>                      NA  \n\n\n\n\nPython\n\n\n\n\nimport pandas as pd\n\npd.merge(employees, positions, how='left')\n\n   muppet_id            names              role  wage_per_hour\n0        1.0  Kermit the Frog  pragmatic leader          75.00\n1        2.0       Miss Piggy          diva pig          85.00\n2        3.0  Fozzie the Bear    stand-up comic          25.25\n3        4.0            Gonzo   stunt performer          54.50\n4        5.0    Rowlf the Dog               NaN            NaN\n\n\n\n\nPower BI\nIn Power BI, we invoke Power Query through the Home >> Transform data menu item.\n\n\n\nExcel\nIn native Excel, there is not a true left join. We can use VLOOKUP() repeatedly to “join” multiples columns in a “left join” manner.\n\n\n\n\n\n\n\nNote\n\n\n\nLike with Power BI, Power Query is also embedded in Excel. We could also use it in Excel (through the Data >> Get Data menu item)."
  },
  {
    "objectID": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html",
    "href": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "",
    "text": "One way to perform dimensionality reduction is through feature selection. In this post, we’ll explore how to create a low-variance feature mask (or filter). We’ll cover both a manual approach with dplyr functions and a more automated, production approach with recipes functions. Enjoy!\n\n\nVariance is important in feature selection because of a concept called information gain. Information gain is what we know about one (usually unknown) variable because we can observe another known variable. In supervised learning, we use information from predictor variables to learn something about the target variable.\nTo make this concrete, imagine we want to estimate loan applicants’ creditworthiness. Though we don’t have their credit scores, we do have their monthly income, age, and number of outstanding loans. If every applicant in our data set has three outstanding loans – that is, the number of outstanding loans didn’t vary – then “outstanding loans” does not differentiate loan applicants and, therefore, does not provide any information about the applicants that we can use to estimate their creditworthiness. Therefore, we’d say that number of outstanding loans provides no information gain about creditworthiness.\nWe can remove features with little to no variance because they are not informative. Consider them useless fluff."
  },
  {
    "objectID": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#setup",
    "href": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#setup",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Setup",
    "text": "Setup\nFor this example, we’ll use a credit score classification data set from Kaggle, provided by Rohan Paris. The data set is large, so I randomly sampled 20% of it. I also did a little data cleaning. As you’ll see, to make this exercise interesting, we’ll add a few low-variance features to demonstrate feature removal.\nYou can download the cleaned data set here.\nSince variance is conceptually simpler with continuous variables, let’s only load the continuous variables into credit_df.\n\nlibrary(tidyverse)\nlibrary(knitr)\n\ncredit_df <- \n  read_csv(\"data/credit_data.csv\") %>% \n  select_if(is.numeric)\n\nHere’s a peek at the data.\n\nkable(credit_df %>% head(5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nannual_income\nmonthly_inhand_salary\nnum_bank_accounts\nnum_credit_card\ninterest_rate\nnum_of_loan\ndelay_from_due_date\nnum_of_delayed_payment\nchanged_credit_limit\nnum_credit_inquiries\noutstanding_debt\ncredit_utilization_ratio\ntotal_emi_per_month\namount_invested_monthly\nmonthly_balance\ncredit_history_months\n\n\n\n\n41\n16176.83\n1585.070\n8\n3\n10\n3\n17\n14\n0.56\n2445\n1200.70\n29.94733\n21.96219\n38.32601\n358.2188\n241\n\n\n36\n82383.04\n6661.253\n3\n5\n8\n4\n17\n14\n1.71\n2\n1218.57\n33.38963\n162.10896\n123.97997\n630.0364\n392\n\n\n44\n28805.34\n2309.445\n8\n3\n5\n2\n13\n19\n7.02\n0\n796.45\n26.83209\n47.19512\n139.90769\n303.8417\n385\n\n\n28\n45412.95\n3520.412\n8\n6\n30\n6\n28\n21\n23.07\n6\n4601.39\n23.41958\n113.69155\n199.56341\n318.7863\n55\n\n\n45\n17296.38\n1480.365\n6\n10\n30\n5\n21\n17\n17.34\n7\n4624.73\n38.39057\n49.36071\n78.16123\n280.5146\n92"
  },
  {
    "objectID": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#calculate-feature-variances",
    "href": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#calculate-feature-variances",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Calculate feature variances",
    "text": "Calculate feature variances\nTo begin, let’s calculate the variance of each column. With dplyr, we’ll use across() to apply var() to all columns with the everything() selector. Notice that we scale() the data before passing it to var(). It is important to normalize the data so the features are comparable with each other. Unnormalized, num_credit_card and monthly income, have very different variances. To compare their influence on creditworthiness in a fair manner, we normalize them.\nWe use tidyr’s pivot_longer() to pivot the scaled variances to columns. We’ll sort them from largest to smallest.\n\ncredit_df %>% \n  summarize(\n    across(everything(), ~ var(scale(., center = FALSE), na.rm = TRUE))) \n\n# A tibble: 1 × 17\n  age[,1] annual_income[,1] monthly_inhand_salary[,1] num_bank_accounts[,1]\n    <dbl>             <dbl>                     <dbl>                 <dbl>\n1  0.0787             0.974                     0.353                 0.978\n# ℹ 13 more variables: num_credit_card <dbl[,1]>, interest_rate <dbl[,1]>,\n#   num_of_loan <dbl[,1]>, delay_from_due_date <dbl[,1]>,\n#   num_of_delayed_payment <dbl[,1]>, changed_credit_limit <dbl[,1]>,\n#   num_credit_inquiries <dbl[,1]>, outstanding_debt <dbl[,1]>,\n#   credit_utilization_ratio <dbl[,1]>, total_emi_per_month <dbl[,1]>,\n#   amount_invested_monthly <dbl[,1]>, monthly_balance <dbl[,1]>,\n#   credit_history_months <dbl[,1]>\n\n\n\ncredit_variances <- credit_df %>% \n  summarize(\n    across(\n        everything(), \n        ~ var(scale(., center = FALSE), na.rm = TRUE))) %>% \n  pivot_longer(\n    everything(), \n    names_to = \"feature\", \n    values_to = \"variance\") %>% \n  arrange(desc(variance)) \n\nkable(credit_variances)\n\n\n\n\nfeature\nvariance\n\n\n\n\nnum_of_loan\n0.98558800\n\n\ninterest_rate\n0.98258481\n\n\nnum_of_delayed_payment\n0.98150878\n\n\nnum_credit_inquiries\n0.97843457\n\n\nnum_bank_accounts\n0.97841843\n\n\ntotal_emi_per_month\n0.97569764\n\n\nannual_income\n0.97397017\n\n\nnum_credit_card\n0.97044729\n\n\namount_invested_monthly\n0.90345646\n\n\noutstanding_debt\n0.41753915\n\n\nmonthly_inhand_salary\n0.35255863\n\n\ndelay_from_due_date\n0.33223435\n\n\nchanged_credit_limit\n0.30855481\n\n\nmonthly_balance\n0.22081631\n\n\ncredit_history_months\n0.15974632\n\n\nage\n0.07874258\n\n\ncredit_utilization_ratio\n0.02527138"
  },
  {
    "objectID": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#set-variance-threshold-and-create-a-mask",
    "href": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#set-variance-threshold-and-create-a-mask",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Set variance threshold and create a mask",
    "text": "Set variance threshold and create a mask\nWe can scan down the variances and identify a natural cut-off between amount_invested_monthly and outstanding_debt, however, that would remove too many features. The next cutoff between credit_history_month and age seems more appropriate. So, we can create a variance filter with a threshold of 0.1.\nWe use pull() to get an array of feature names that we can use as a mask.\n\nlow_var_filter <- credit_variances %>% \n  filter(variance < 0.1) %>% \n  pull(feature)\n\nlow_var_filter\n\n[1] \"age\"                      \"credit_utilization_ratio\""
  },
  {
    "objectID": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#apply-the-mask",
    "href": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#apply-the-mask",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Apply the mask",
    "text": "Apply the mask\nWe then apply the mask to the data frame. Notice that it removes ‘age’ and credit_utilization_ratio.\n\nfiltered_credit_df <- credit_df %>% \n  select(-all_of(low_var_filter))\n\nkable(filtered_credit_df %>% head(5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nannual_income\nmonthly_inhand_salary\nnum_bank_accounts\nnum_credit_card\ninterest_rate\nnum_of_loan\ndelay_from_due_date\nnum_of_delayed_payment\nchanged_credit_limit\nnum_credit_inquiries\noutstanding_debt\ntotal_emi_per_month\namount_invested_monthly\nmonthly_balance\ncredit_history_months\n\n\n\n\n16176.83\n1585.070\n8\n3\n10\n3\n17\n14\n0.56\n2445\n1200.70\n21.96219\n38.32601\n358.2188\n241\n\n\n82383.04\n6661.253\n3\n5\n8\n4\n17\n14\n1.71\n2\n1218.57\n162.10896\n123.97997\n630.0364\n392\n\n\n28805.34\n2309.445\n8\n3\n5\n2\n13\n19\n7.02\n0\n796.45\n47.19512\n139.90769\n303.8417\n385\n\n\n45412.95\n3520.412\n8\n6\n30\n6\n28\n21\n23.07\n6\n4601.39\n113.69155\n199.56341\n318.7863\n55\n\n\n17296.38\n1480.365\n6\n10\n30\n5\n21\n17\n17.34\n7\n4624.73\n49.36071\n78.16123\n280.5146\n92"
  },
  {
    "objectID": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#load-data-with-categorical-variables",
    "href": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#load-data-with-categorical-variables",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Load data with categorical variables",
    "text": "Load data with categorical variables\nTo demonstrate the recipes approach, we’ll load all the features, so we have both continuous and categorical variables.\n\ncredit_df <- \n  read_csv(\"data/credit_data.csv\")\n\nTo make this example interesting, we’ll insert a couple of low-variance features – num_credit_card and num_credit_inquiries.\n\ncredit_df <- credit_df %>% \n  mutate(\n    num_credit_card_rand = runif(n()),\n    num_credit_inquiries_rand = runif(n()),\n    num_credit_card = if_else(\n      num_credit_card_rand < .95, 5, num_credit_card),\n    num_credit_inquiries = if_else(\n      num_credit_inquiries_rand < .95, 3, num_credit_inquiries)\n  ) %>% \n  select(-num_credit_card_rand, -num_credit_inquiries_rand)"
  },
  {
    "objectID": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#define-a-recipe-object",
    "href": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#define-a-recipe-object",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Define a recipe object",
    "text": "Define a recipe object\nThen we define a recipe object. Notice the first parameter is a formula. We define credit_score as the target variable and all other features as predictor variables.\nWe add the step_zv() step first. No-variance features will cause problems when we normalize the data with step_scale(). We apply the no-variance step to all predictors and the scale step to only the numeric predictors. Then, we apply step_nzv() to remove low-variance features. prep() “fits” the recipe to the data.\n\nlibrary(recipes) \n\nlow_variance_recipe <- recipe(credit_score ~ ., data = credit_df) %>%\n  step_zv(all_predictors()) %>%\n  step_scale(all_numeric_predictors()) %>%\n  step_nzv(all_predictors()) %>%\n  prep()\n\nWe can use tidy() to peek into the recipe and see the effect it will have on the trained data set it was trained on. Here we look at the third step of the recipe – step_nzv(). We can see that it will remove our two low-variance features – num_credit_card and num_credit_inquiries.\n\ntidy(low_variance_recipe, number = 3)\n\n# A tibble: 2 × 2\n  terms                id       \n  <chr>                <chr>    \n1 num_credit_card      nzv_nAlyV\n2 num_credit_inquiries nzv_nAlyV"
  },
  {
    "objectID": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#apply-the-recipe-to-credit_df",
    "href": "blog/dataprep/low_variance_mask/simple-low-variance-feature-selection-mask-in-r.html#apply-the-recipe-to-credit_df",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Apply the recipe to credit_df",
    "text": "Apply the recipe to credit_df\nIn recipes to apply a trained recipe to a data set, we can use bake(). The new_data parameter allows us to specify the data set “bake” the recipe with. If we pass NULL, it will bake the same data that the recipe was trained on.\n\nfiltered_credit_df <- low_variance_recipe %>% bake(new_data = NULL)\n\nnames(filtered_credit_df)\n\n [1] \"month\"                    \"age\"                     \n [3] \"occupation\"               \"annual_income\"           \n [5] \"monthly_inhand_salary\"    \"num_bank_accounts\"       \n [7] \"interest_rate\"            \"num_of_loan\"             \n [9] \"delay_from_due_date\"      \"num_of_delayed_payment\"  \n[11] \"changed_credit_limit\"     \"outstanding_debt\"        \n[13] \"credit_utilization_ratio\" \"payment_of_min_amount\"   \n[15] \"total_emi_per_month\"      \"amount_invested_monthly\" \n[17] \"payment_behaviour\"        \"monthly_balance\"         \n[19] \"credit_history_months\"    \"credit_score\"            \n\n\nIf we compare the names in the original credit_df to the names in the filtered_credit_df, we can see that num_credit_card and num_credit_inquiries were removed.\n\nsetdiff(names(credit_df), names(filtered_credit_df))\n\n[1] \"num_credit_card\"      \"num_credit_inquiries\""
  },
  {
    "objectID": "blog/dataprep/outer_join/outer_join.html",
    "href": "blog/dataprep/outer_join/outer_join.html",
    "title": "Outer Join",
    "section": "",
    "text": "A outer join keeps all the rows from both the right and left tables and inserts NULLs when a matching row is not found in the other table.\nThis Venn diagram illustrates which rows are included in a outer join."
  },
  {
    "objectID": "blog/dataprep/outer_join/outer_join.html#how-does-a-outer-join-work",
    "href": "blog/dataprep/outer_join/outer_join.html#how-does-a-outer-join-work",
    "title": "Outer Join",
    "section": "How does a outer join work?",
    "text": "How does a outer join work?\nA outer join visits every row in the left table and then checks if there is a matching row in the right table. If there is, it combines the matching left and right row. If there is not a match, it inserts NULLs in the right columns. If there are additional primary key values in the right table that were not already inserted from the left table, it inserts those with nulls in the left table columns (since those ids were not found in the left table…only the right table).\nIn short, a full outer join is the unique set of rows found in both a left and right join (that’s called the intersection – not to be confused with the intersection of a left and right table. That’s an inner join!).\n\n\n\n\n\n\nLeft Table\n\n\n\n\n\n\n\nRight Table\n\n\n\n\n\n\n\n\n\nOuter Joined Result\n\n\n\n\n\nNotice how the last row in the left table (id=5, name=\"Rowlf the Dog) and the last row in the right table (id=-8, role=\"frenzied monster drummer\", wage_per_hour=45.75) both appear in the final result with NULLs column values that came from the opposite table.\nThe Data School provides a nice explanation of the row by row operations for an outer join – demonstrating that an outer join is a left join combined with a right join."
  },
  {
    "objectID": "blog/dataprep/outer_join/outer_join.html#how-many-records-end-up-in-the-result-of-an-inner-join",
    "href": "blog/dataprep/outer_join/outer_join.html#how-many-records-end-up-in-the-result-of-an-inner-join",
    "title": "Outer Join",
    "section": "How many records end up in the result of an inner join?",
    "text": "How many records end up in the result of an inner join?\n\\(L =\\) # of records in the left table\n\\(R =\\) # of records in the right table\nMin number of records \\(L\\) (# of records in the left table)\nThis is the case where all the rows in the left and right tables match.\nMax number of records \\(L\\) + \\(R\\)\nThis is the case where there are no matching rows."
  },
  {
    "objectID": "blog/dataprep/outer_join/outer_join.html#implementing-a-outer-join-in-different-tools",
    "href": "blog/dataprep/outer_join/outer_join.html#implementing-a-outer-join-in-different-tools",
    "title": "Outer Join",
    "section": "Implementing a outer join in different tools",
    "text": "Implementing a outer join in different tools\nHere is how you perform a outer join in R, Python, Power BI, and Excel.\n\nR\n\nlibrary(dplyr)\n\nemployees %>% \n  full_join(positions, by = \"muppet_id\")\n\n# A tibble: 6 × 4\n  muppet_id names           role                     wage_per_hour\n      <dbl> <chr>           <chr>                            <dbl>\n1         1 Kermit the Frog pragmatic leader                  75  \n2         2 Miss Piggy      diva pig                          85  \n3         3 Fozzie the Bear stand-up comic                    25.2\n4         4 Gonzo           stunt performer                   54.5\n5         5 Rowlf the Dog   <NA>                              NA  \n6         8 <NA>            frenzied monster drummer          45.8\n\n\n\n\nPython\n\n\n\n\nimport pandas as pd\n\npd.merge(employees, positions, how='outer')\n\n   muppet_id            names                      role  wage_per_hour\n0        1.0  Kermit the Frog          pragmatic leader          75.00\n1        2.0       Miss Piggy                  diva pig          85.00\n2        3.0  Fozzie the Bear            stand-up comic          25.25\n3        4.0            Gonzo           stunt performer          54.50\n4        5.0    Rowlf the Dog                       NaN            NaN\n5        8.0              NaN  frenzied monster drummer          45.75\n\n\n\n\nPower BI\nIn Power BI, we invoke Power Query through the Home >> Transform data menu item.\n\n\n\nExcel\nIn native Excel, there is not a true outer join. The best we can do is mimic an outer join in two steps. First, we combine the primary key values from both the left and right tables and eliminate duplicates with the “Remove Duplicates” feature. Second, we use those unique primary key values to merge the columns together by using VLOOKUP() repeatedly.\n\n\n\n\n\n\n\nNote\n\n\n\nYou can invoke Power Query in Excel (through the Data >> Get Data menu item) to perform a true outer join."
  },
  {
    "objectID": "blog/dataprep/regex_preserve_currency_tokens/regex-preserve_currency_tokens.html",
    "href": "blog/dataprep/regex_preserve_currency_tokens/regex-preserve_currency_tokens.html",
    "title": "regex to Preserve Currency Tokens",
    "section": "",
    "text": "Introduction\nI’ve been working to collect a corpus of tax legislation, regulations, and court cases. At the core of my corpus is the United States Code Title 26 (USC26), otherwise known as the Internal Revenue Code or the U.S. Tax Code. I’m using the corpus to train a tax-specific word embedding. Word embeddings capture similarity semantics of tokens (words, or multi-word phrases) by encoding them into an n-dimensional space. Similar tokens are embedded into the n-dimensional space in close proximity.\nSince currency values may have important semantic meaning in the USC–for instance, tax bracket boundaries–I want to preserve them so the tokenizer does not break them apart. To do this, I want to replace spaces, commas, decimals, and dollar signs with underscores. Here are some examples:\n\nExamples of Currency Values\n\n\nOriginal\nPreserved\n\n\n\n\n$172,175\n172_175_usd\n\n\n$2.5 million\n2_5_million_usd\n\n\n$56,750.25\n56_750_25_usd\n\n\n\n\n\nImplementation\nThe approach I took was to first match the different currency formats and then pass the match to a helper function that would replace spaces, commas, decimals, and dollar signs with underscores.\nHere is the pattern I created to match currency tokens:\n\npattern = r'\\$\\d{0,3}(\\,\\d{3}){0,4}(\\.\\d{1,2})?( (million|billion))?'\n\n\n\\$ matches a dollar sign.\n\\d{0,3} The number after the dollar sign and before a comma or decimal boundary. Looking for 0 to 3 digits allows for these patterns: $.75, $125,000, etc.\n(\\,\\d{3}){0,4}(\\.\\d{1,2})? matches repeated comma boundaries (if they exist) and two-decimal places for cents (if they exist). More specifically:\n\n(\\,\\d{3}) matches “,xxx”. With the addition of {0,4} it matches “,xxx” repeatedly–up to trillions (which is probably overkill for the USC26 because most large currency values have “million” or “billion” text suffixes).\n(\\.\\d{1,2})? matches an optional cents.\n\n( (million|billion))? just checks for a text suffix (the ? at the end makes it optional.)\n\nNext, here is a simple helper function to replace spaces, commas, decimals, and dollar signs with underscores and tack on “_usd” at the end. Python’s string replace() method is faster than the regex sub(), so I went with replace().\n\nimport re\n\ndef replace_currency_parts(match):\n    text = match.group(0).replace(\" \", \"_\").replace(\".\", \"_\").replace(',', '_')\n    if (text[0] == '$'):\n        text = text[1:] + \"_usd\"\n    return text\n\nNow I need a test string.\n\ntest_string = \"I made $755.34 billion this year, $5.34 million last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45 in case that's a more realistic salary in my life.\"\n\nThen I compile the regex and replace matches. Notice that the second argument of sub() can take a method that returns a string. I leverage this to call the helper function.\n\ncompiled_pattern = re.compile(pattern)\ncompiled_pattern.sub(replace_currency_parts, test_string)\n\n\"I made 755_34_billion_usd this year, 5_34_million_usd last year, but I also want to match 125_234_34_usd and 1_342_40_usd and 45_09_usd and 45_usd in case that's a more realistic salary in my life.\"\n\n\nHere is the full Python implementation.\n\nimport time\nimport timeit\n\npattern = r'\\$\\d{0,3}(\\,\\d{3}){0,4}(\\.\\d{1,2})?( (million|billion))?'\n\ndef replace_currency_parts(match):\n    text = match.group(0).replace(\" \", \"_\").replace(\".\", \"_\").replace(',', '_')\n    if (text[0] == '$'):\n        text = text[1:] + \"_usd\"\n    return text\n\ntest_string = \"I made $355.34 million this year, $435.34 billion last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45.\"\n\ncompiled_pattern = re.compile(pattern)\ncompiled_pattern.sub(replace_currency_parts, test_string)\n\n\n\nR Implementation\nI was curious if python was that much faster than R. So, here is an R implementation. Like Python’s sub(), the str_replace_all function can take a helper function.\n\nlibrary(stringr)\n\npattern <- '\\\\$\\\\d{0,3}(\\\\,\\\\d{3}){0,4}(\\\\.\\\\d{1,2})?( (million|billion))?'\n\nreplace_currency_parts <- function(match) {\n  \n  text <- match %>% \n    str_replace_all(\" \", \"_\") %>% \n    str_replace_all(\"\\\\.\", \"_\") %>% \n    str_replace_all(\"\\\\,\", \"_\")\n    \n  if (str_sub(text, 1, 1) == \"$\"){\n    text <- str_c(str_sub(text, 2), \"_usd\")\n  }\n    \n  return(text)\n}\n\ntest_string <-  \"I made $355.34 million this year, $435.34 billion last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45.\"\n\nstr_replace_all(test_string, pattern, replace_currency_parts)\n\n[1] \"I made 355_34_million_usd this year, 435_34_billion_usd last year, but I also want to match 125_234_34_usd and 1_342_40_usd and 45_09_usd and 45_usd.\"\n\n\n\n\nWhich is faster?\nSo, which is faster?\nI compare the Python and R implementations by taking the average of 1000 executions of the code. Since the {stringr} package in R is higher level–there’s no option to compile the regex ahead of time and keep it out of the loop–I placed the Python regex compile code inside the loop to make a more fair comparison. In both cases, the units are milliseconds. NOTE: The python time() method returns seconds, so I convert.\n\nfrom time import time\n\nstart_ms = int(round(time() * 1000))\nfor i in range(1000):\n  compiled_pattern = re.compile(pattern)\n  str = compiled_pattern.sub(replace_currency_parts, test_string)\nend_ms = int(round(time() * 1000))\n\nprint(\"elapsed ms = \", (end_ms-start_ms)/1000)\n\nelapsed ms =  0.029\n\n\n\nlibrary(microbenchmark)\n\nmicrobenchmark::microbenchmark(str_replace_all(test_string, pattern, replace_currency_parts), times = 1000)\n\nUnit: milliseconds\n                                                          expr    min      lq\n str_replace_all(test_string, pattern, replace_currency_parts) 3.4897 4.28405\n     mean median     uq     max neval\n 5.462372 5.2396 6.3352 14.1053  1000\n\n\nI don’t know what overhead is included in the {stringr} package, but it’s about two orders of magnitude slower than Python. I suspect it is because the Python replace() string method is quite speedy."
  },
  {
    "objectID": "blog/dataprep/right_join/right_join.html",
    "href": "blog/dataprep/right_join/right_join.html",
    "title": "Right Join",
    "section": "",
    "text": "A right join keeps all the rows from the right table and inserts NULLs on the left when there is not a matching row found in the left table.\nThis Venn diagram illustrates which rows are included in a right join.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA right join is the mirror of a left join."
  },
  {
    "objectID": "blog/dataprep/right_join/right_join.html#how-does-a-right-join-work",
    "href": "blog/dataprep/right_join/right_join.html#how-does-a-right-join-work",
    "title": "Right Join",
    "section": "How does a right join work?",
    "text": "How does a right join work?\nA right join visits every row in the right table and then checks if there is a matching row in the left table. If there is, it combines the matching left and right row. If there is not, it places nulls on the left side.\n\n\n\n\n\n\nLeft Table\n\n\n\n\n\n\n\nRight Table\n\n\n\n\n\n\n\n\n\nRight Joined Result\n\n\n\n\n\nNotice how the last row (id=-8, role=\"frenzied monster drummer\", wage_per_hour=45.75) in the right table does not have a match in the left table. So, nulls are inserted into the left columns of the result.\nThe Data School provides a nice animation of the row by row operations for a right join."
  },
  {
    "objectID": "blog/dataprep/right_join/right_join.html#how-many-records-end-up-in-the-result-of-an-inner-join",
    "href": "blog/dataprep/right_join/right_join.html#how-many-records-end-up-in-the-result-of-an-inner-join",
    "title": "Right Join",
    "section": "How many records end up in the result of an inner join?",
    "text": "How many records end up in the result of an inner join?\n\\(L =\\) # of records in the left table\n\\(R =\\) # of records in the right table\nThe number of records in the final left join is \\(R\\)."
  },
  {
    "objectID": "blog/dataprep/right_join/right_join.html#implementing-a-right-join-in-different-tools",
    "href": "blog/dataprep/right_join/right_join.html#implementing-a-right-join-in-different-tools",
    "title": "Right Join",
    "section": "Implementing a right join in different tools",
    "text": "Implementing a right join in different tools\nHere is how you perform a right join in R, Python, Power BI, and Excel.\n\nR\n\nlibrary(dplyr)\n\nemployees %>% \n  right_join(positions, by = \"muppet_id\")\n\n# A tibble: 5 × 4\n  muppet_id names           role                     wage_per_hour\n      <dbl> <chr>           <chr>                            <dbl>\n1         1 Kermit the Frog pragmatic leader                  75  \n2         2 Miss Piggy      diva pig                          85  \n3         3 Fozzie the Bear stand-up comic                    25.2\n4         4 Gonzo           stunt performer                   54.5\n5         8 <NA>            frenzied monster drummer          45.8\n\n\n\n\nPython\n\n\n\n\nimport pandas as pd\n\npd.merge(employees, positions, how='right')\n\n   muppet_id            names                      role  wage_per_hour\n0        1.0  Kermit the Frog          pragmatic leader          75.00\n1        2.0       Miss Piggy                  diva pig          85.00\n2        3.0  Fozzie the Bear            stand-up comic          25.25\n3        4.0            Gonzo           stunt performer          54.50\n4        8.0              NaN  frenzied monster drummer          45.75\n\n\n\n\nPower BI\nIn Power BI, we invoke Power Query through the Home >> Transform data menu item.\n\n\n\nExcel\nIn native Excel, there is not a true right join. As demonstrated in the left join post, we can use VLOOKUP() repeatedly to “join” multiples columns in a “left join” manner. Since a right join mirrors a left join; to perform a left join, we can simply swap the left and right tables then perform a left join with VLOOKUP(). It’s not ideal, but it illustrates how similar interchangeable left and right joins are.\n\n\n\n\n\n\n\nNote\n\n\n\nYou can invoke Power Query in Excel (through the Data >> Get Data menu item) to perform a true right join."
  },
  {
    "objectID": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html",
    "href": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "",
    "text": "Semi-annually, members of The Church of Jesus Christ of Latter-day Saints gather across the world for General Conference (GC) to hear messages and talks about the gospel of Jesus Christ. These messages are delivered by prophets, apostles, and other leaders in the Church. GC occurs the first weekend of April and October. Although general conferences have occurred since the founding of the Church in 1830, [talks (and their text)] since 1971 are available on the Church’s website(https://www.churchofjesuschrist.org/study/general-conference).\nGC is one of my favorite times of the year! Seriously! For me, it competes with Christmas.\nNaturally, I’m curious about the topics that are taught at GC. I wanted to apply NLP topic modeling to GC."
  },
  {
    "objectID": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#about-the-data",
    "href": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#about-the-data",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "About the data",
    "text": "About the data\nI was able to scrape the data from the GC website.\nEvery semi-annual conference has 4-5 sessions. Each session contains a series of talks. There are approximately 36-40 talks across all sessions in a conference. Every talk will be a document in topic modeling. Since I have the GC dates, I can study the topics longitudinally. I’m specifically curious about how the frequency of different topics has changed over the decades.\nI start simple and only deal with unigrams."
  },
  {
    "objectID": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#objective",
    "href": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#objective",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Objective",
    "text": "Objective\nMy objective in this post is to fit a topic model to the GC corpus. Therefore, I need to find the number of topics that best fits the data.\nThe approach is very similar to clustering – another unsupervised algorithm. I’ll fit topic models using a range of different numbers of topics (20-topic model, 22-topic model,…,n-topic). Then calculate the divergence of each model and find the model with the maximum divergence.\n\nPerplexity is also a common metric used to explore the optimal number of topics. I use divergence because it is implemented in the seededlda package.\n\nI’ll then qualitatively assess a smaller range of models near the optimal divergence range.\nThis post will demonstrate the beginning of this iterative quantitative-qualitative process to finding the optimal number of topics."
  },
  {
    "objectID": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#preparing-the-data",
    "href": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#preparing-the-data",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Preparing the data",
    "text": "Preparing the data\nI used the tidytext package1 to tokenize the General Conference (GC) talks into unigrams. I removed common stopwords and did basic data cleaning. I then used cast_dfm() to convert the tidy text data frame to a document-feature matrix (DFM) compatible with quanteda. This blog post starts with this DFM of the GC talks.\nquanteda does not implement topic models, so I’ll use the Latent Dirichlet Allocation (LDA) implementation provided by the seededlda package to create the topic model."
  },
  {
    "objectID": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#loading-the-data",
    "href": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#loading-the-data",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Loading the data",
    "text": "Loading the data\nI saved the DFM in an RDS format for quick retrieval. Let’s load the data and take a look at its dimensions.\n\nlibrary(tidyverse)\nlibrary(quanteda)\nunigram_dfm <- read_rds(\"data/unigram_dfm.rds\")\ndim(unigram_dfm)\n\n[1]  3881 16336\n\n\nThe matrix represents 3,881 documents (GC talks) and 16,336 words (unigrams). Keep in mind that many stopwords (e.g., the, and, am, etc.) were removed. The hope is that the remaining words are significant and salient."
  },
  {
    "objectID": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#the-topic-model",
    "href": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#the-topic-model",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "The topic model",
    "text": "The topic model\nLike clustering algorithms, LDA requires that we specify the number of topics to fit. With close to 4k talks and 16k+ words, it wasn’t clear to me how many topics I should fit. To discover this, I leveraged the divergence metric of the topic model. seededlda, in its divergence() function, implements the Kullback-Leibler (KL) divergence, which is frequently used to measure the dissimilarities between word distributions (i.e., topics) 2.\nIn a nutshell, the logic of topic divergence is like this:\n\nTopics consist of individual words. For example,\n\nFamily: children, family, home, parents, love, god, husband, wife\nMissionary Work: mission, missionary, serve, gospel, elder, lord\nSavior: love, christ, jesus, savior, father, heart\n\nThe words that make up topics can overlap, meaning that the words can appear in several topics. For instance, love appears in both the Savior and Family topics.\nWhen we minimize the overlap, or maximize the divergence, of topics; then we have some assurance that we have the most distinct and useful topics.\n\nTo find the optimal number of topics, I fit topic models with 2 to 52 topics.\n\nNote: There was a bit of trial and error to arrive at that range.\n\nThen I plotted their divergence scores to see where they maxed out.\nSince fitting LDA models is computationally expensive, I used the furrr package – the parallelized version of purrr – on my high-powered server to fit all those models.\nThen I combined the divergence score with each topic model into a data frame, so I could plot them.\n\nlibrary(seededlda)\nlibrary(furrr)\n\n# create a vector for number of topics to fit\nn <- seq(2, 52, by = 2)\n\n# helper function that fits the LDA model and computes the divergence\n# this is to parallelize the code with the 'furrr' package\nget_div_score <- function(dfm, k) {\n  lda_fit <- textmodel_lda(dfm, k)\n  return(divergence(lda_fit))\n}\n\n# setup four threads\nplan(multisession, workers = 4)\n\n# fit models in parallel\ndiv_scores <- n %>% \n  future_map_dbl(\n    ~get_div_score(unigram_dfm, k = .x),\n    furrr_options(seed = TRUE))\n\n# assemble a df with number of topics and divergence scores\ndiv_score_df <- tibble(\n  num_topics = n,\n  div_score = div_scores\n)\n\n\n\n\n\nFinding the maximum divergence – the quantitative part\nHere’s the code to create the number of topics vs. divergence plot.\n\n# plot topic number vs divergence score\ndiv_score_df %>% \n  ggplot(aes(x = num_topics, y = div_score)) +\n  geom_point() +\n  ylab(\"Divergence Score\") +\n  xlab(\"Number of Topics\") +\n  geom_hline(yintercept = max(div_score_df$div_score), \n             color = \"blue\", \n             linetype = \"dashed\") +\n  annotate(\"text\", \n           x=30, \n           y=max(div_score_df$div_score)+0.01, \n           label=\"0.436\",\n           color = \"blue\") +\n  ggtitle(\"Number of Topics vs Divergence\")\n\n\n\n\nIn the end, it was easier to just view the top three results in a table.\n\ndiv_score_df %>% \n  arrange(desc(div_score)) %>% \n  head(5)\n\n# A tibble: 5 × 2\n  num_topics div_score\n       <dbl>     <dbl>\n1         30     0.436\n2         32     0.435\n3         28     0.434\n4         24     0.433\n5         26     0.433\n\n\n\n\nInterpreting the topics – the qualitative part\nWhile the 30-topic model has the highest divergence, maximal divergence does not necessarily mean that that number of topics is maximally meaningful. So I took the models with the top three divergence scores (32-topic, 30-topic, and 28-topics) and explored the quality of the topics.\nI created these models in parallel on my server. Here’s the code:\n\nn <- c(28, 30, 32)\n\nplan(multisession, workers = 3)\nlda_fits <- n %>% \n  future_map(\n    ~textmodel_lda(unigram_dfm, k = .x),\n    furrr_options(seed = TRUE))\n\nAfter the 28-, 30-, and 32-topics models were fit, I created labels for each topic based on the words that the topic was composed of to evaluate the topic quality. Here I’ll demonstrate this process with the 30- and 32-topic models.\nI extracted the words per topic with the terms() function and formed them into a tibble for ease of reading. Then I proceeded to subjectively interpret the topics based on the top 10 words in each topic. I don’t believe there is a way to avoid this. Notice that I updated the column names with meaningful labels.\nIt is expected that there will be some noisy topics. If the topic wasn’t clear to me, I labeled it with question marks.\n\n\n\n\nlibrary(knitr) \n\nlda30_df <- as_tibble(terms(lda_fits[[2]]))\n\nnames(lda30_df) <- \n  c(\"01_Lost_Sheep\",\n    \"02_Jesus_Christ_Savior\", \n    \"03_Priesthood_Leaders_Responsibility\",\n    \"04_Spiritual_Light_of_the_World\",\n    \"05_Gospel_Scripture_Study\",\n    \"06_Sins_Repentace_Atonement\", \n    \"07_Lords_People_Zion??\",\n    \"08_Missionary_Service\",\n    \"09_Joseph_Smith\",\n    \"10_Church_Welfare_Fast_Offerings\",\n    \"11_???\",\n    \"12_Book_of_Mormon_Scripture_Reading\",\n    \"13_???\",\n    \"14_Priesthood_Power_Keys\",\n    \"15_Sustain_Church_Officers\",\n    \"16_Holy_Ghost_Testimony\",\n    \"17_Love_of_God_Jesus_Christ\",\n    \"18_Prayer\",\n    \"19_Time_to_Choose_Eternal_Life\",\n    \"20_Relief_Society\",\n    \"21_Sacrament_Sabbath_Day\",\n    \"22_Temple_Covenants_Blessings\",\n    \"23_Gods_Plan_Eternal_Life\",\n    \"24_???\",\n    \"25_Morals_Standards??\",\n    \"26_Faith_in_Jesus_Christ\",\n    \"27_??\", \n    \"28_Prophet_President\",\n    \"29_???\",\n    \"30_Family_Home\"\n    )\n\nkable(lda30_df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01_Lost_Sheep\n02_Jesus_Christ_Savior\n03_Priesthood_Leaders_Responsibility\n04_Spiritual_Light_of_the_World\n05_Gospel_Scripture_Study\n06_Sins_Repentace_Atonement\n07_Lords_People_Zion??\n08_Missionary_Service\n09_Joseph_Smith\n10_Church_Welfare_Fast_Offerings\n11_???\n12_Book_of_Mormon_Scripture_Reading\n13_???\n14_Priesthood_Power_Keys\n15_Sustain_Church_Officers\n16_Holy_Ghost_Testimony\n17_Love_of_God_Jesus_Christ\n18_Prayer\n19_Time_to_Choose_Eternal_Life\n20_Relief_Society\n21_Sacrament_Sabbath_Day\n22_Temple_Covenants_Blessings\n23_Gods_Plan_Eternal_Life\n24_???\n25_Morals_Standards??\n26_Faith_in_Jesus_Christ\n27_??\n28_Prophet_President\n29_???\n30_Family_Home\n\n\n\n\nsheep\njesus\nchurch\nlight\ngospel\nrepentance\nlord\nmission\njoseph\nwelfare\nalma\nbook\nbrother\npriesthood\nmanifest\nholy\nlove\nfather\nlife\nwomen\nsacrament\ntemple\ngod\nchurch\ngod\nfaith\ntime\npresident\nlord\nchildren\n\n\nwater\nchrist\npriesthood\npeace\nchurch\nsins\ngod\nmissionaries\nsmith\nchurch\nne\nmormon\nhome\nchurch\npresidency\nspirit\nchrist\nprayer\ntime\nsociety\nday\ncovenants\neternal\npeople\nevil\nchrist\ndon’t\nlord\nthy\nfamily\n\n\nking\nson\nbishop\nworld\nlearn\nchrist\npeople\nmissionary\nchurch\npoor\ngod\nread\nmother\npower\nsustain\nghost\njesus\nheavenly\npath\nrelief\nremember\nblessings\nlife\nlord\nworld\njesus\nday\nchurch\nthou\nhome\n\n\ngod\nfather\nquorum\nchrist\nteach\natonement\nworld\ngospel\nprophet\nservices\nmosiah\nchrist\nhand\nauthority\npresident\ngod\nchurch\ngod\nhappiness\nsisters\nsabbath\ncovenant\nfather\nconference\nlife\ngod\nlife\nprophet\nye\nparents\n\n\nlost\ngod\nstake\ndarkness\nprinciples\njesus\nearth\nserve\ngod\nlord\nlord\nscriptures\npresident\nbrethren\nfavor\nlord\nsavior\npray\nhope\nwoman\nsacrifice\nordinances\nplan\nworld\npeople\nlord\nboy\ngod\ngod\nfamilies\n\n\nlord\njohn\nward\nspiritual\ntaught\nsin\nday\nchurch\nchrist\ntithing\njesus\njesus\nlife\naaronic\ntwelve\ntestimony\ngod\nlove\nlives\nsister\ntime\nfamily\nearth\nsaints\nmoral\ntestimony\nhome\nconference\nthee\nlove\n\n\nlife\nlife\npresident\nlife\nstudy\nrepent\nland\nlord\njesus\nfast\nye\ngod\nwords\nkeys\nproposed\nchrist\nday\nlord\neternal\ndaughters\nsunday\nlord\nchrist\ntemple\nlord\npower\ntold\nkimball\nshalt\nmarriage\n\n\ndavid\ndeath\nleaders\ntime\nspiritual\nsavior\nzion\ntime\ngospel\npeople\npatience\nwords\nday\nhold\nquorum\nreceive\nlife\nfeel\nchoose\nchurch\nmeeting\nsacred\nworld\nbuilding\nsatan\nlives\nschool\nprophets\ncommandments\nmother\n\n\nshepherd\nworld\nhome\ngospel\nscriptures\nmercy\nnations\nservice\nday\nfamily\npeople\nnephi\nfound\ngod\nchurch\ngift\ngospel\nson\nlord\npresident\nmusic\nreceive\njesus\nday\nstandards\nlife\nfather\nhinckley\nmatt\nfather\n\n\ntime\nsavior\nresponsibility\ntruth\ndoctrine\ngod\ntime\nelder\nearth\nfood\nheart\nword\nago\nlord\ncounselor\npower\nsisters\nheart\nfollow\nworld\nsacred\ntemples\nlord\nsisters\nlive\ngospel\nlove\ncalled\nwords\nwife\n\n\n\n\n\n\nlda32_df <- as_tibble(terms(lda_fits[[1]]))\n\nnames(lda32_df) <- \n  c(\"01_Sustain_Church_Officers\",\n    \"02_Repentence\",\n    \"03_Church_Audit_Financial\",\n    \"04_Gospel_Scripture_Study\",\n    \"05_Jesus_Christ_Resurrection\",\n    \"06_Spiritual_Light_of_the_World\",\n    \"07_???\",\n    \"08_???\",\n    \"09_Prophet_President\",\n    \"10_Tithing\",\n    \"11_Standards_Against_Evil??\",\n    \"12_Priesthood_Power_Keys\",\n    \"13_Conference???\",\n    \"14_Book_of_Mormon_Joseph_Smith\",\n    \"15_Holy_Ghost_Prayer_Testimony\",\n    \"16_Marriage_Family\",\n    \"17_Church_Leaders\",\n    \"18_Church_Welfare_Fast_Offerings\",\n    \"19_Gods_Plan_Eternal_Life\",\n    \"20_Covenants\",\n    \"21_Joy_Suffering_Faith\",\n    \"22_Tree_of_Life_Path???\",\n    \"23_Missionary_Service\",\n    \"24_Church_of_Jesus_Christ\",\n    \"25_Faith_in_Jesus_Christ\",\n    \"26_Temple_Ordinances\",\n    \"27_Lords_People???\",\n    \"28_Love_Jesus_Christ\",  \n    \"29_???\", # I think this is my garbage topic\n    \"30_Relief_Society_Women\",\n    \"31_Family_Home\",\n    \"32_???\" # I think this is a garbage topic too\n    )\n\nkable(lda32_df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01_Sustain_Church_Officers\n02_Repentence\n03_Church_Audit_Financial\n04_Gospel_Scripture_Study\n05_Jesus_Christ_Resurrection\n06_Spiritual_Light_of_the_World\n07_???\n08_???\n09_Prophet_President\n10_Tithing\n11_Standards_Against_Evil??\n12_Priesthood_Power_Keys\n13_Conference???\n14_Book_of_Mormon_Joseph_Smith\n15_Holy_Ghost_Prayer_Testimony\n16_Marriage_Family\n17_Church_Leaders\n18_Church_Welfare_Fast_Offerings\n19_Gods_Plan_Eternal_Life\n20_Covenants\n21_Joy_Suffering_Faith\n22_Tree_of_Life_Path???\n23_Missionary_Service\n24_Church_of_Jesus_Christ\n25_Faith_in_Jesus_Christ\n26_Temple_Ordinances\n27_Lords_People???\n28_Love_Jesus_Christ\n29_???\n30_Relief_Society_Women\n31_Family_Home\n32_???\n\n\n\n\nmanifest\nalma\nchurch\ngospel\njesus\nlight\nking\nbrother\npresident\nlord\nevil\npriesthood\nchurch\nbook\nholy\nmarriage\nchurch\nwelfare\nlife\ncovenants\nlife\nlife\nmission\nchurch\nfaith\ntemple\nlord\nlove\ntime\nwomen\nchildren\nthou\n\n\npresidency\nsins\nprogram\nscriptures\ngod\ndarkness\nlord\nhome\nchurch\ntithing\nworld\npower\npeople\nmormon\nspirit\nlove\nbishop\nchurch\ngod\ncovenant\njoy\nwater\nmissionaries\nchrist\nchrist\nfamily\npeople\nchrist\ndon’t\nsociety\nfamily\nthy\n\n\nsustain\nrepentance\ndepartment\nlearn\nchrist\nne\ngod\nmother\nprophet\npay\npeople\nlord\nconference\njoseph\nghost\nwife\nquorum\npoor\neternal\nlord\nsuffering\njourney\nmissionary\njesus\npeace\ntemples\ngod\njesus\nlife\nrelief\nhome\nlord\n\n\npresident\nchrist\nauditing\nstudy\nfather\ngod\ncourage\nhand\nlord\nsacrifice\ngod\nbrethren\nsaints\nsmith\nlord\ngod\nward\nservices\nplan\nsacrament\nlord\npath\nchurch\ngod\nhope\nordinances\nearth\ngod\nday\nsisters\nparents\nye\n\n\nfavor\ngod\nmembership\nspiritual\nlife\njesus\nisrael\nfather\ngod\nmoney\nstandards\ngod\nsalt\nprophet\nfather\nlife\nstake\nfast\ncommandments\nday\njesus\ntree\nserve\ngospel\njesus\nlord\nworld\nsavior\nfather\nwoman\nfather\ngod\n\n\nproposed\nsin\nfunds\nteach\nson\nspiritual\ndavid\nwords\njoseph\nday\nmoral\nauthority\ncity\nread\ngod\nchildren\nhome\nprogram\nhappiness\nholy\ngod\nchrist\ngospel\nworld\nlord\nhouse\nday\nfather\ndidn’t\nsister\nfamilies\nthee\n\n\nquorum\nrepent\neducation\ntaught\ndeath\nworld\nstand\nago\nconference\nblessings\nsatan\naaronic\nlake\nchrist\nprayer\nfamily\npresident\npeople\nfather\nblessings\nfaith\ntime\nservice\nday\ngod\nblessings\nland\nsisters\nschool\nchurch\nlove\njesus\n\n\ntwelve\nye\ncouncil\nword\nworld\ntime\ndaniel\nday\nsmith\ntime\nyouth\nkeys\nlord\ngod\npray\nhusband\nleaders\nprinciples\nchoose\nchrist\npain\njesus\ntime\ntruth\npower\nsacred\ntime\nheavenly\nboy\npresident\nteach\nshalt\n\n\ncounselor\njesus\nfinancial\nchrist\nresurrection\nchrist\npeople\npresident\nkimball\npeople\nlife\nhold\nday\njesus\nwords\neternal\npriesthood\nfood\nheavenly\nsacred\nhealing\nfollow\nlord\nearth\nlife\ndead\nnations\nfeel\nremember\ndaughters\nmother\nmatt\n\n\nchurch\natonement\npercent\nprinciples\nearth\ntruth\nhand\nlife\nprophets\nlife\nclean\nduty\nworld\nlord\ntestimony\nwoman\nteachers\nfamily\ngod’s\nremember\ntrials\nday\nelder\ntrue\nlives\ntime\ndays\nheart\nfriends\nmother\nchild\nlove\n\n\n\n\n\n\n\nBattle: 30-topic vs 32-topic\nTo wrap my mind around the pros and cons of the two models. I captured some of the differences in this table.\n\nThis is where contextual knowledge of the data is needed.\n\n\n\n\n\n\n\n\n30-Topic Model\n32-Topic Model\n\n\n\n\nBook of Mormon gets paired with scriptures and scripture reading. Joseph Smith has his own topic.\nBook of Mormon gets paired with joseph smith\n\n\nPrayer has its own topic.\nprayer gets placed inside the The Holy Ghost and Testimony topic.\n\n\nJesus Christ is paired with savior\nJesus Christ is paired with resurrection.\n\n\nSeems to have a Lost Sheep topic.\nThere is not topic that contains sheep.\n\n\nsacrament is paired with sabbath day (topic #21)\nsacrament is paired with covenants.\n\n\ntithing is found under the Church Welfare topic.\ntithing is paired with sacrifice and pay, which seems to solidly form a Tithing topic\n\n\n\nI like the fact that Joseph Smith has his own topic in the 30-topic model; and, it probably makes more sense to bundle the Book of Mormon with scriptures (since it is part of the scriptural canon of The Church of Jesus Christ of Latter-day Saints) than it does with Joseph Smith (who translated it). A strong nudge to favor the 30-topic model.\nPrayer and Christ’s direction to find and feed His “lost sheep” are both very common topics in GC talks. The 30-topic has separate topics for each of these. That’s a couple of votes for the 30-topic model.\nI especially like that the Jesus Christ topic contains savior. I prefer that associate as Savior over the associate with resurrection in the 32-topic model. I view His resurrection as part of His saving.\nMembers of the Church meet together on Sundays (the Sabbath day) to partake of the Sacrament (i.e., the Lord’s Supper), so it’s very appropriate to associate the Sacrament with the Sabbath day. However, the Sacrament is a time for church members to remember the covenants they made at baptism; so it’s equally appropriate to associate the Sacrament with covenants as well. So, this point is a wash.\nTithing as its own topic (in the 32-topic model) is appealing. A win for the 32-topic model. However, tithing is often spoken of in the context of fast offerings. Fast offerings are free-will monetary offerings given in conjunction with a fast – the money saved from skipping meals during the fast is donated to help the poor and needy. A counter for the 30-topic model. But the 32-topic option highlights tithing in terms of sacrifice. You might consider tithing as a baseline measure of an individual’s willingness to sacrifice for the Lord. A stronger counter for the 32-topic model.\nSo, overall, we’ll go with the 30-topic model.\n\nAs I explored models with more topics, I discovered that other topics crystalized, examples include youth and the latter days, home teaching (a program to ensure members of the church are taken care of and watched over), pioneers and trek to Salt Lake City, and revelation.\n\nLet’s pull out the 30-topic model.\n\nlda30_fit <- lda_fits[[2]]"
  },
  {
    "objectID": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#exploring-results",
    "href": "blog/nlp/gc_topic_model/gc_topic_model_best_fit.html#exploring-results",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Exploring results",
    "text": "Exploring results\nNow that we have a finalized topic model, let’s look at the results.\nFirst, I’ll use the LDA model to predict the topic of each of the talks. To do this, I’ll use topics(lda30_fit). That returns a named list, like this:\n\nhead(topics(lda30_fit))\n\n       1971_04_a_witness_and_a_blessing 1971_04_all_may_share_in_adams_blessing \n                                 topic9                                 topic22 \n               1971_04_be_slow_to_anger             1971_04_choose_you_this_day \n                                 topic4                                  topic7 \n        1971_04_drink_of_the_pure_water   1971_04_eternal_joy_is_eternal_growth \n                                topic26                                 topic23 \n30 Levels: topic1 topic2 topic3 topic4 topic5 topic6 topic7 topic8 ... topic30\n\n\nSo, I assemble a data frame with the doc_ids and the topic_ids.\n\nlibrary(lubridate)\n\n# assemble doc_ids and topics\ntalk_topics_df <- \n  tibble(\n    doc_id = names(topics(lda30_fit)),\n    topic_id = topics(lda30_fit)) %>% \n  mutate(conf_date = str_sub(doc_id, 1, 7) %>% \n           str_replace(\"_\", \"-\") %>%  ym())\n\nSince the topic_ids are not very helpful, I’ll combine them with the topic labels I created above and join them into the talk data frame.\n\n# create a topic label map, to get more meaningful labels\ntopic_df <- tibble(\n  topic_id = str_c(\"topic\", 1:30),\n  topic_label = str_sub(names(lda30_df), 4))\n\n# join topic labels in\ntalk_topics_df <- \n  talk_topics_df %>% left_join(topic_df)\n\nI’d like to explore the number of talks at each conference over time, so I’ll aggregate the topic counts for each conference.\n\n# get topic counts in each conference\nconf_topic_counts_df <- \n  talk_topics_df %>% \n  count(conf_date, topic_label)\n\nNow, we are ready to plot. I did quite a bit of exploration and came across this plot. I found it interesting that the “Love_of_God_Jesus_Christ” topic has become more prevalent since about 2010.\n\nconf_topic_counts_df %>% \n  filter(topic_label == \"Love_of_God_Jesus_Christ\") %>% \n  ggplot(aes(x=conf_date, y=n)) +\n  geom_col(fill = \"purple\") +\n  theme(legend.position = \"none\")\n\n\n\n\nHere is a list of the top 20 words in the Love_of_God_Jesus_Christ topic (it was topic 17).\n\nterms(lda30_fit, 20)[, 17]\n\n [1] \"love\"     \"christ\"   \"jesus\"    \"church\"   \"savior\"   \"god\"     \n [7] \"day\"      \"life\"     \"gospel\"   \"sisters\"  \"brothers\" \"people\"  \n[13] \"lives\"    \"heart\"    \"serve\"    \"service\"  \"world\"    \"children\"\n[19] \"follow\"   \"feel\""
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Inner Join\n\n\n\n\n\n\n\n\n\n\n\n\nMatt Pickard\n\n\n\n\n\n\n  \n\n\n\n\nLeft Join\n\n\n\n\n\n\n\n\n\n\n\n\nMatt Pickard\n\n\n\n\n\n\n  \n\n\n\n\nOuter Join\n\n\n\n\n\n\n\n\n\n\n\n\nMatt Pickard\n\n\n\n\n\n\n  \n\n\n\n\nRight Join\n\n\n\n\n\n\n\n\n\n\n\n\nMatt Pickard\n\n\n\n\n\n\n  \n\n\n\n\nExcel Conditional Aggregation Functions (COUNTIFS, SUMIFS, AVERAGEIFS)\n\n\n\n\n\n\n\nexcel\n\n\naggregation\n\n\nconditional aggregation\n\n\nsummarization\n\n\n\n\nData aggregation involves combing multiple data points into a single number. This post shows how to use Excel to aggregate rows of data that meet certain conditions.\n\n\n\n\n\n\nFeb 21, 2023\n\n\nMatt Pickard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nseededlda Topic Model - Finding the best fit\n\n\n\n\n\n\n\ntopic modeling\n\n\nnlp\n\n\nmultithread\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2023\n\n\nMatt Pickard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple Feature Selection Using a Low-to-No Variance Mask\n\n\n\n\n\n\n\n\n\n\nDemonstrates how to remove features with low to no variance.\n\n\n\n\n\n\nJan 5, 2023\n\n\nMatt Pickard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregex to Preserve Currency Tokens\n\n\n\n\n\n\n\nregex\n\n\ndata preparation\n\n\npython\n\n\nr\n\n\n\n\nDevelopment of a regex to preserve currency values in the U.S. Tax Code.\n\n\n\n\n\n\nMar 14, 2022\n\n\nMatt Pickard\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "A place to showcase my projects.\n\n\n\n\n\n\n\n\n\nNo matching items"
  }
]
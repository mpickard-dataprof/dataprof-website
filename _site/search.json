[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "regex to Preserve Currency Tokens\n\n\n\n\n\n\n\nregex\n\n\ndata preparation\n\n\n\n\nDevelopment of a regex to preserve currency values in the U.S. Tax Code.\n\n\n\n\n\n\nMar 14, 2022\n\n\nMatt Pickard\n\n\n\n\n\n\n\n\nUsing xgboost and sklearn to Predict Loan Default\n\n\n\n\n\n\n\npython\n\n\nmachine learning\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2022\n\n\nMatt Pickard\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Education\nBrigham Young University | Provo, UT\nB.S. in Computer Engineering | 2002\nBrigham Young University | Provo, UT\nMBA in Operations and Information Systems | 2008\nUniversity of Arizona | Tucson, AZ\nPh.D. in Management Information Systems | 2012\n\n\nExperience\nNational Instruments\nApplications Engineer | 2002 - 2004\nSoftware Engineer / Project Manager | 2004 - 2006\nRaytheon Missile Systems\nTechnical Instructor | 2010\nSandia National Labs\nFaculty Summer Intern - Data Analytics | 2017\nUniversity of New Mexico\nAssistant Professor of AIS and Analytics | 2012-2018\nNorthern Illinois University\nAssociate Professor of Data and Analytics | 2018-present"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/using-xgboost-and-sklearn-to-predict-loan-default/index.en.html",
    "href": "posts/using-xgboost-and-sklearn-to-predict-loan-default/index.en.html",
    "title": "Using xgboost and sklearn to Predict Loan Default",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd \n\nIntroduction\nI wanted to combine xgboost with sklearn pipelines to process a pandas DataFrame. Special thanks to Kaggle user M Yasser H for supplying the Loan Default Dataset.\n\n\nLoad the data\n# Load the data\nloan_df = pd.read_csv(\"../data/Loan_Default.csv\")\n\n\nCreate labels and features\nThe loan status (whether or not the customer defaulted on the loan) is the target variable. We’ll extract that out as our labels. The other columns (minus the ID) will serve as our features. And we’ll take a peek at our features.\n# Split out labels and features, encode labels as integers\ny = loan_df['Status']\n\nX = loan_df.loc[:,~loan_df.columns.isin(['ID','Status'])]\n\n\nSimple data exploration\nTake a peek as our feature variables.\nX.head()\n##    year loan_limit             Gender  ... Region Security_Type dtir1\n## 0  2019         cf  Sex Not Available  ...  south        direct  45.0\n## 1  2019         cf               Male  ...  North        direct   NaN\n## 2  2019         cf               Male  ...  south        direct  46.0\n## 3  2019         cf               Male  ...  North        direct  42.0\n## 4  2019         cf              Joint  ...  North        direct  39.0\n## \n## [5 rows x 32 columns]\nNotice there is a mix of categorical and continuous variables.\nLet’s check if there are any missing values.\nX.isnull().sum()\n## year                             0\n## loan_limit                    3344\n## Gender                           0\n## approv_in_adv                  908\n## loan_type                        0\n## loan_purpose                   134\n## Credit_Worthiness                0\n## open_credit                      0\n## business_or_commercial           0\n## loan_amount                      0\n## rate_of_interest             36439\n## Interest_rate_spread         36639\n## Upfront_charges              39642\n## term                            41\n## Neg_ammortization              121\n## interest_only                    0\n## lump_sum_payment                 0\n## property_value               15098\n## construction_type                0\n## occupancy_type                   0\n## Secured_by                       0\n## total_units                      0\n## income                        9150\n## credit_type                      0\n## Credit_Score                     0\n## co-applicant_credit_type         0\n## age                            200\n## submission_of_application      200\n## LTV                          15098\n## Region                           0\n## Security_Type                    0\n## dtir1                        24121\n## dtype: int64\n\n\nPreprocessing\nSince we have a mix of continuous and categorical variables, we’ll setup an imputers for each type of variable. So, we are going to separate teh continous and the categorical varabiles into separate DataFrames.\nFor the continuous variables, we’ll impute the median.\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.impute import SimpleImputer\n\n# extract numeric columns\nnumeric_mask = (X.dtypes != object)\nnumeric_columns = X.columns[numeric_mask].tolist()\nnumeric_df = X[numeric_columns]\n\n# create \"imputer\", just going to fill missing values with \"missing\"\nnumeric_imputor = DataFrameMapper(\n  [([numeric_feature], SimpleImputer(strategy='median')) for numeric_feature in numeric_df],\n  input_df=True,\n  df_out=True\n  )\nFor the categorical variables, we’ll impute the value ‘missing’.\n# extract categorical features\ncategorical_mask = (X.dtypes == object)\ncategorical_columns = X.columns[categorical_mask].tolist()\ncategorical_df = X[categorical_columns]\n\ncategorical_imputor = DataFrameMapper(\n  [([categorical_feature], SimpleImputer(strategy='constant', fill_value = \"missing\")) for categorical_feature in categorical_df],\n  input_df=True,\n  df_out=True\n  )\n\n\nBuild the pipeline\nWe are going to use sklearn’s DictVectorizer, which operates on numpy arrays/matrices. So to make it compatiable with DataFrames, we’ll create a simple utility class to allow a DataFrame to be passed through the pipeline. Thanks to Chanseok for the dictifier code.\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n# Define Dictifier class to turn df into dictionary as part of pipeline\nclass Dictifier(BaseEstimator, TransformerMixin):\n  def fit(self, X, y=None):\n    return self\n  \n  def transform(self, X):\n    if type(X) == pd.core.frame.DataFrame:\n      return X.to_dict(\"records\")\n    else:\n      return pd.DataFrame(X).to_dict(\"records\")\nNow we build the pipeline. Notice how we use the FeatureUnion to bring the continous and categorical features back together again at the start of the pipeline.\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction import DictVectorizer\nimport xgboost as xgb\n\nimputed_df = FeatureUnion([\n  ('num_imputer', numeric_imputor),\n  ('cat_imputer', categorical_imputor)    \n  ])\n  \nxgb_pipeline = Pipeline([\n  (\"featureunion\", imputed_df),\n  ('dictifier', Dictifier()),\n  ('dict_vectorizer', DictVectorizer(sort=False)),\n  (\"xgb\", xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n  ])\n\n\n3-Fold Cross Validation\nWe’ll use 3-fold cross validation (instead of 10, or something greater) to minimize compute time.\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(xgb_pipeline, X, y, scoring=\"f1\", cv=3)\navg_f1 = np.mean(np.sqrt(np.abs(scores)))\nprint(\"Avg F1 Score:\", avg_f1)\n## Avg F1 Score: 0.9999863537583441\n\n\nConclusions\nThe average F1 score is suspiciously high, so let’s not put much clout in the quality of the model. But it serves the purpose of demonstrating how to pass a ‘pandas’ DataFrame through an sklearn pipeline, preprocess mixed variable (continuous and categorical) data, and build an xgboost classifier.\nJust because it’s bugging me, here are a few things that may need to be improved in this model:\n\nThere is probably a high correlation between the target variable and some feature variables. We can check this quickly. Fille the NAs with zero and correlate it with the loan status (which is 0 and 1).\n\nnumeric_fillna_df = numeric_df.fillna(0)\nnumeric_fillna_df.corrwith(y)\n## year                         NaN\n## loan_amount            -0.036825\n## rate_of_interest       -0.958875\n## Interest_rate_spread   -0.392977\n## Upfront_charges        -0.431183\n## term                   -0.000675\n## property_value         -0.273267\n## income                 -0.044620\n## Credit_Score            0.004004\n## LTV                    -0.267700\n## dtir1                  -0.325613\n## dtype: float64\nWe can see that rate_of_interest has a high inverse correlation with the target variable. However, I did try removing rate_of_interest and still ended up with an F1 score of 0.9999.\n\nFind a better way to impute the missing categorical. Chirag Goyal enumerates some options in this post. I suspect that building a model to predict missing values would be an option. Another simpler option would be to just randomly insert existing values. But, currently, with the imputer in this post, it is essentially treating ‘missing’ as a legit value."
  },
  {
    "objectID": "posts/using-xgboost-and-sklearn-to-predict-loan-default/index.html",
    "href": "posts/using-xgboost-and-sklearn-to-predict-loan-default/index.html",
    "title": "Using xgboost and sklearn to Predict Loan Default",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd \n\n\nIntroduction\nI wanted to combine xgboost with sklearn pipelines to process a pandas DataFrame. Special thanks to Kaggle user M Yasser H for supplying the Loan Default Dataset.\n\n\nLoad the data\n\n# Load the data\nloan_df = pd.read_csv(\"Loan_Default.csv\")\n\n\n\nCreate labels and features\nThe loan status (whether or not the customer defaulted on the loan) is the target variable. We’ll extract that out as our labels. The other columns (minus the ID) will serve as our features. And we’ll take a peek at our features.\n\n# Split out labels and features, encode labels as integers\ny = loan_df['Status']\n\nX = loan_df.loc[:,~loan_df.columns.isin(['ID','Status'])]\n\n\n\nSimple data exploration\nTake a peek as our feature variables.\n\nX.head()\n\n\n\n\n\n  \n    \n      \n      year\n      loan_limit\n      Gender\n      approv_in_adv\n      loan_type\n      loan_purpose\n      Credit_Worthiness\n      open_credit\n      business_or_commercial\n      loan_amount\n      ...\n      income\n      credit_type\n      Credit_Score\n      co-applicant_credit_type\n      age\n      submission_of_application\n      LTV\n      Region\n      Security_Type\n      dtir1\n    \n  \n  \n    \n      0\n      2019\n      cf\n      Sex Not Available\n      nopre\n      type1\n      p1\n      l1\n      nopc\n      nob/c\n      116500\n      ...\n      1740.0\n      EXP\n      758\n      CIB\n      25-34\n      to_inst\n      98.728814\n      south\n      direct\n      45.0\n    \n    \n      1\n      2019\n      cf\n      Male\n      nopre\n      type2\n      p1\n      l1\n      nopc\n      b/c\n      206500\n      ...\n      4980.0\n      EQUI\n      552\n      EXP\n      55-64\n      to_inst\n      NaN\n      North\n      direct\n      NaN\n    \n    \n      2\n      2019\n      cf\n      Male\n      pre\n      type1\n      p1\n      l1\n      nopc\n      nob/c\n      406500\n      ...\n      9480.0\n      EXP\n      834\n      CIB\n      35-44\n      to_inst\n      80.019685\n      south\n      direct\n      46.0\n    \n    \n      3\n      2019\n      cf\n      Male\n      nopre\n      type1\n      p4\n      l1\n      nopc\n      nob/c\n      456500\n      ...\n      11880.0\n      EXP\n      587\n      CIB\n      45-54\n      not_inst\n      69.376900\n      North\n      direct\n      42.0\n    \n    \n      4\n      2019\n      cf\n      Joint\n      pre\n      type1\n      p1\n      l1\n      nopc\n      nob/c\n      696500\n      ...\n      10440.0\n      CRIF\n      602\n      EXP\n      25-34\n      not_inst\n      91.886544\n      North\n      direct\n      39.0\n    \n  \n\n5 rows × 32 columns\n\n\n\nNotice there is a mix of categorical and continuous variables.\nLet’s check if there are any missing values.\n\nX.isnull().sum()\n\nyear                             0\nloan_limit                    3344\nGender                           0\napprov_in_adv                  908\nloan_type                        0\nloan_purpose                   134\nCredit_Worthiness                0\nopen_credit                      0\nbusiness_or_commercial           0\nloan_amount                      0\nrate_of_interest             36439\nInterest_rate_spread         36639\nUpfront_charges              39642\nterm                            41\nNeg_ammortization              121\ninterest_only                    0\nlump_sum_payment                 0\nproperty_value               15098\nconstruction_type                0\noccupancy_type                   0\nSecured_by                       0\ntotal_units                      0\nincome                        9150\ncredit_type                      0\nCredit_Score                     0\nco-applicant_credit_type         0\nage                            200\nsubmission_of_application      200\nLTV                          15098\nRegion                           0\nSecurity_Type                    0\ndtir1                        24121\ndtype: int64\n\n\n\n\nPreprocessing\nSince we have a mix of continuous and categorical variables, we’ll setup an imputers for each type of variable. So, we are going to separate teh continous and the categorical varabiles into separate DataFrames.\nFor the continuous variables, we’ll impute the median.\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.impute import SimpleImputer\n\n# extract numeric columns\nnumeric_mask = (X.dtypes != object)\nnumeric_columns = X.columns[numeric_mask].tolist()\nnumeric_df = X[numeric_columns]\n\n# create \"imputer\", just going to fill missing values with \"missing\"\nnumeric_imputor = DataFrameMapper(\n  [([numeric_feature], SimpleImputer(strategy='median')) for numeric_feature in numeric_df],\n  input_df=True,\n  df_out=True\n  )\n\nFor the categorical variables, we’ll impute the value ‘missing’.\n\n# extract categorical features\ncategorical_mask = (X.dtypes == object)\ncategorical_columns = X.columns[categorical_mask].tolist()\ncategorical_df = X[categorical_columns]\n\ncategorical_imputor = DataFrameMapper(\n  [([categorical_feature], SimpleImputer(strategy='constant', fill_value = \"missing\")) for categorical_feature in categorical_df],\n  input_df=True,\n  df_out=True\n  )\n\n\n\nBuild the pipeline\nWe are going to use sklearn’s DictVectorizer, which operates on numpy arrays/matrices. So to make it compatiable with DataFrames, we’ll create a simple utility class to allow a DataFrame to be passed through the pipeline. Thanks to Chanseok for the dictifier code.\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n# Define Dictifier class to turn df into dictionary as part of pipeline\nclass Dictifier(BaseEstimator, TransformerMixin):\n  def fit(self, X, y=None):\n    return self\n  \n  def transform(self, X):\n    if type(X) == pd.core.frame.DataFrame:\n      return X.to_dict(\"records\")\n    else:\n      return pd.DataFrame(X).to_dict(\"records\")\n\nNow we build the pipeline. Notice how we use the FeatureUnion to bring the continous and categorical features back together again at the start of the pipeline.\n\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction import DictVectorizer\nimport xgboost as xgb\n\nimputed_df = FeatureUnion([\n  ('num_imputer', numeric_imputor),\n  ('cat_imputer', categorical_imputor)    \n  ])\n  \nxgb_pipeline = Pipeline([\n  (\"featureunion\", imputed_df),\n  ('dictifier', Dictifier()),\n  ('dict_vectorizer', DictVectorizer(sort=False)),\n  (\"xgb\", xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n  ])\n\nC:\\Users\\A1849763\\Anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning:\n\npandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n\n\n\n\n\n3-Fold Cross Validation\nWe’ll use 3-fold cross validation (instead of 10, or something greater) to minimize compute time.\n\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(xgb_pipeline, X, y, scoring=\"f1\", cv=3)\navg_f1 = np.mean(np.sqrt(np.abs(scores)))\nprint(\"Avg F1 Score:\", avg_f1)\n\nAvg F1 Score: 0.9999863537583441\n\n\n\n\nConclusions\nThe average F1 score is suspiciously high, so let’s not put much clout in the quality of the model. But it serves the purpose of demonstrating how to pass a ‘pandas’ DataFrame through an sklearn pipeline, preprocess mixed variable (continuous and categorical) data, and build an xgboost classifier.\nJust because it’s bugging me, here are a few things that may need to be improved in this model:\n\nThere is probably a high correlation between the target variable and some feature variables. We can check this quickly. Fille the NAs with zero and correlate it with the loan status (which is 0 and 1).\n\n\nnumeric_fillna_df = numeric_df.fillna(0)\nnumeric_fillna_df.corrwith(y)\n\nyear                         NaN\nloan_amount            -0.036825\nrate_of_interest       -0.958875\nInterest_rate_spread   -0.392977\nUpfront_charges        -0.431183\nterm                   -0.000675\nproperty_value         -0.273267\nincome                 -0.044620\nCredit_Score            0.004004\nLTV                    -0.267700\ndtir1                  -0.325613\ndtype: float64\n\n\nWe can see that rate_of_interest has a high inverse correlation with the target variable. However, I did try removing rate_of_interest and still ended up with an F1 score of 0.9999.\n\nFind a better way to impute the missing categorical. Chirag Goyal enumerates some options in this post. I suspect that building a model to predict missing values would be an option. Another simpler option would be to just randomly insert existing values. But, currently, with the imputer in this post, it is essentially treating ‘missing’ as a legit value."
  },
  {
    "objectID": "posts/regex-preserve_currency_tokens/index.html",
    "href": "posts/regex-preserve_currency_tokens/index.html",
    "title": "regex to Preserve Currency Tokens",
    "section": "",
    "text": "Introduction\nI’ve been working to collect a corpus of tax legislation, regulations, and court cases. At the core of my corpus is the United States Code Title 26 (USC26), otherwise known as the Internal Revenue Code or the U.S. Tax Code. I’m using the corpus to train a tax-specific word embedding. Word embeddings capture similarity semantics of tokens (words, or multi-word phrases) by encoding them into a n-dimensional space. Similar tokens are embedded into the n-dimensional space in close proximity.\nSince currency values may have important semantic meaning in the USC–for instance, tax bracket boundaries–I want to preserve them so the tokenizer does not break them apart. To do this, I want to replace spaces, commas, decimals, and dollar signs with underscores. Here are some examples:\n\n\n\nOriginal\nPreserved\n\n\n\n\n$172,175\n172_175_usd\n\n\n$2.5 million\n2_5_million_usd\n\n\n$56,750.25\n56_750_25_usd\n\n\n\n\n\nImplementation\nThe approach I took was to first match the different currency formats and then pass the match to a helper function that would replace spaces, commas, decimals, and dollar signs with underscores.\nHere is the pattern I created to match currency tokens:\n\npattern = r'\\$\\d{0,3}(\\,\\d{3}){0,4}(\\.\\d{1,2})?( (million|billion))?'\n\n\n\\$ matches a dollar sign.\n\\d{0,3} The number after the dollar sign and before a comma or decimal boundary. Looking for 0 to 3 digits allows for these patterns: $.75, $125,000, etc.\n(\\,\\d{3}){0,4}(\\.\\d{1,2})? matches repeated comma boundaries (if they exist) and two-decimal places for cents (if they exist). More specifically:\n\n(\\,\\d{3}) matches “,xxx”. With the addition of {0,4} it matches “,xxx” repeatedly–up to trillions (which is probably overkill for the USC26 because most large currency values have “million” or “billion” text suffixes).\n(\\.\\d{1,2})? matches an optional cents.\n\n( (million|billion))? just checks for a text suffix (the ? at the end makes it optional.)\n\nNext, here is a simple helper function to replace spaces, commas, decimals, and dollar signs with underscores and tack on “_usd” at the end. Python’s string replace() method is faster than the regex sub(), so I went with replace().\n\nimport re\n\ndef replace_currency_parts(match):\n    text = match.group(0).replace(\" \", \"_\").replace(\".\", \"_\").replace(',', '_')\n    if (text[0] == '$'):\n        text = text[1:] + \"_usd\"\n    return text\n\nNow I need a test string.\n\ntest_string = \"I made $755.34 billion this year, $5.34 million last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45 in case that's a more realistic salary in my life.\"\n\nThen I compile the regex and replace matches. Notice that the second argument of sub() can take a method that returns a string. I leverage this to call the helper function.\n\ncompiled_pattern = re.compile(pattern)\ncompiled_pattern.sub(replace_currency_parts, test_string)\n\n\"I made 755_34_billion_usd this year, 5_34_million_usd last year, but I also want to match 125_234_34_usd and 1_342_40_usd and 45_09_usd and 45_usd in case that's a more realistic salary in my life.\"\n\n\nHere is the full Python implementation.\n\nimport time\nimport timeit\n\npattern = r'\\$\\d{0,3}(\\,\\d{3}){0,4}(\\.\\d{1,2})?( (million|billion))?'\n\ndef replace_currency_parts(match):\n    text = match.group(0).replace(\" \", \"_\").replace(\".\", \"_\").replace(',', '_')\n    if (text[0] == '$'):\n        text = text[1:] + \"_usd\"\n    return text\n\ntest_string = \"I made $355.34 million this year, $435.34 billion last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45.\"\n\ncompiled_pattern = re.compile(pattern)\ncompiled_pattern.sub(replace_currency_parts, test_string)\n\n\n\nR Implementation\nI was curious if python was that much faster than R. So, here is an R implementation. Like Python’s sub(), the str_replace_all function can take a helper function.\n\nlibrary(stringr)\n\npattern <- '\\\\$\\\\d{0,3}(\\\\,\\\\d{3}){0,4}(\\\\.\\\\d{1,2})?( (million|billion))?'\n\nreplace_currency_parts <- function(match) {\n  \n  text <- match %>% \n    str_replace_all(\" \", \"_\") %>% \n    str_replace_all(\"\\\\.\", \"_\") %>% \n    str_replace_all(\"\\\\,\", \"_\")\n    \n  if (str_sub(text, 1, 1) == \"$\"){\n    text <- str_c(str_sub(text, 2), \"_usd\")\n  }\n    \n  return(text)\n}\n\ntest_string <-  \"I made $355.34 million this year, $435.34 billion last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45.\"\n\nstr_replace_all(test_string, pattern, replace_currency_parts)\n\n[1] \"I made 355_34_million_usd this year, 435_34_billion_usd last year, but I also want to match 125_234_34_usd and 1_342_40_usd and 45_09_usd and 45_usd.\"\n\n\n\n\nWhich is faster?\nSo, which is faster?\nI compare the Python and R implementations by taking the average of 1000 executions of the code. Since the {stringr} package in R is higher level–there’s no option to compile the regex ahead of time and keep it out of the loop–I placed the Python regex compile code inside the loop to make a more fair comparison. In both cases, the units are milliseconds. NOTE: The python time() method returns seconds, so I convert.\n\nfrom time import time\n\nstart_ms = int(round(time() * 1000))\nfor i in range(1000):\n  compiled_pattern = re.compile(pattern)\n  str = compiled_pattern.sub(replace_currency_parts, test_string)\nend_ms = int(round(time() * 1000))\n\nprint(\"elapsed ms = \", (end_ms-start_ms)/1000)\n\nelapsed ms =  0.021\n\n\n\nlibrary(microbenchmark)\n\nmicrobenchmark::microbenchmark(str_replace_all(test_string, pattern, replace_currency_parts), times = 1000)\n\nUnit: milliseconds\n                                                          expr    min      lq\n str_replace_all(test_string, pattern, replace_currency_parts) 1.9412 2.00845\n     mean median     uq    max neval\n 2.181681 2.0652 2.2058 9.9199  1000\n\n\nI don’t know what overhead is included in the {stringr} package, but it’s about two orders of magnitude slower than Python. I suspect it is because the Python replace() string method is quite speedy."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "test\n\n\n\n\n\n\n\n\n\n\n\n\nMatt Pickard\n\n\n\n\n\n\n\n\nseededlda Topic Model - Finding the best fit\n\n\n\n\n\n\n\ntopic modeling\n\n\nnlp\n\n\nmultithread\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2023\n\n\nMatt Pickard\n\n\n\n\n\n\n\n\nSimple Feature Selection Using a Low-to-No Variance Mask\n\n\n\n\n\n\n\n\n\n\nDemonstrates how to remove features with low to no variance.\n\n\n\n\n\n\nJan 5, 2023\n\n\nMatt Pickard\n\n\n\n\n\n\n\n\nregex to Preserve Currency Tokens\n\n\n\n\n\n\n\nregex\n\n\ndata preparation\n\n\npython\n\n\nr\n\n\n\n\nDevelopment of a regex to preserve currency values in the U.S. Tax Code.\n\n\n\n\n\n\nMar 14, 2022\n\n\nMatt Pickard\n\n\n\n\n\n\n\n\nUsing xgboost and sklearn to Predict Loan Default\n\n\n\n\n\n\n\npython\n\n\nmachine learning\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2022\n\n\nMatt Pickard\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "A place to showcase my projects."
  },
  {
    "objectID": "blog/posts/using-xgboost-and-sklearn-to-predict-loan-default.html",
    "href": "blog/posts/using-xgboost-and-sklearn-to-predict-loan-default.html",
    "title": "Using xgboost and sklearn to Predict Loan Default",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd \n\n\nIntroduction\nI wanted to combine xgboost with sklearn pipelines to process a pandas DataFrame. Special thanks to Kaggle user M Yasser H for supplying the Loan Default Dataset.\n\n\nLoad the data\n\n# Load the data\nloan_df = pd.read_csv(\"data/Loan_Default.csv\")\n\n\n\nCreate labels and features\nThe loan status (whether or not the customer defaulted on the loan) is the target variable. We’ll extract that out as our labels. The other columns (minus the ID) will serve as our features. And we’ll take a peek at our features.\n\n# Split out labels and features, encode labels as integers\ny = loan_df['Status']\n\nX = loan_df.loc[:,~loan_df.columns.isin(['ID','Status'])]\n\n\n\nSimple data exploration\nTake a peek at our feature variables.\n\nX.head()\n\n\n\n\n\n  \n    \n      \n      year\n      loan_limit\n      Gender\n      approv_in_adv\n      loan_type\n      loan_purpose\n      Credit_Worthiness\n      open_credit\n      business_or_commercial\n      loan_amount\n      ...\n      income\n      credit_type\n      Credit_Score\n      co-applicant_credit_type\n      age\n      submission_of_application\n      LTV\n      Region\n      Security_Type\n      dtir1\n    \n  \n  \n    \n      0\n      2019\n      cf\n      Sex Not Available\n      nopre\n      type1\n      p1\n      l1\n      nopc\n      nob/c\n      116500\n      ...\n      1740.0\n      EXP\n      758\n      CIB\n      25-34\n      to_inst\n      98.728814\n      south\n      direct\n      45.0\n    \n    \n      1\n      2019\n      cf\n      Male\n      nopre\n      type2\n      p1\n      l1\n      nopc\n      b/c\n      206500\n      ...\n      4980.0\n      EQUI\n      552\n      EXP\n      55-64\n      to_inst\n      NaN\n      North\n      direct\n      NaN\n    \n    \n      2\n      2019\n      cf\n      Male\n      pre\n      type1\n      p1\n      l1\n      nopc\n      nob/c\n      406500\n      ...\n      9480.0\n      EXP\n      834\n      CIB\n      35-44\n      to_inst\n      80.019685\n      south\n      direct\n      46.0\n    \n    \n      3\n      2019\n      cf\n      Male\n      nopre\n      type1\n      p4\n      l1\n      nopc\n      nob/c\n      456500\n      ...\n      11880.0\n      EXP\n      587\n      CIB\n      45-54\n      not_inst\n      69.376900\n      North\n      direct\n      42.0\n    \n    \n      4\n      2019\n      cf\n      Joint\n      pre\n      type1\n      p1\n      l1\n      nopc\n      nob/c\n      696500\n      ...\n      10440.0\n      CRIF\n      602\n      EXP\n      25-34\n      not_inst\n      91.886544\n      North\n      direct\n      39.0\n    \n  \n\n5 rows × 32 columns\n\n\n\nNotice there is a mix of categorical and continuous variables.\nLet’s check if there are any missing values.\n\nX.isnull().sum()\n\nyear                             0\nloan_limit                    3344\nGender                           0\napprov_in_adv                  908\nloan_type                        0\nloan_purpose                   134\nCredit_Worthiness                0\nopen_credit                      0\nbusiness_or_commercial           0\nloan_amount                      0\nrate_of_interest             36439\nInterest_rate_spread         36639\nUpfront_charges              39642\nterm                            41\nNeg_ammortization              121\ninterest_only                    0\nlump_sum_payment                 0\nproperty_value               15098\nconstruction_type                0\noccupancy_type                   0\nSecured_by                       0\ntotal_units                      0\nincome                        9150\ncredit_type                      0\nCredit_Score                     0\nco-applicant_credit_type         0\nage                            200\nsubmission_of_application      200\nLTV                          15098\nRegion                           0\nSecurity_Type                    0\ndtir1                        24121\ndtype: int64\n\n\n\n\nPreprocessing\nSince we have a mix of continuous and categorical variables, we’ll set up an imputer for each type of variable. So, we are going to separate the continuous and the categorical variables into separate DataFrames.\nFor the continuous variables, we’ll impute the median.\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.impute import SimpleImputer\n\n# extract numeric columns\nnumeric_mask = (X.dtypes != object)\nnumeric_columns = X.columns[numeric_mask].tolist()\nnumeric_df = X[numeric_columns]\n\n# create \"imputer\", just going to fill missing values with \"missing\"\nnumeric_imputor = DataFrameMapper(\n  [([numeric_feature], SimpleImputer(strategy='median')) for numeric_feature in numeric_df],\n  input_df=True,\n  df_out=True\n  )\n\nFor the categorical variables, we’ll impute the value ‘missing’.\n\n# extract categorical features\ncategorical_mask = (X.dtypes == object)\ncategorical_columns = X.columns[categorical_mask].tolist()\ncategorical_df = X[categorical_columns]\n\ncategorical_imputor = DataFrameMapper(\n  [([categorical_feature], SimpleImputer(strategy='constant', fill_value = \"missing\")) for categorical_feature in categorical_df],\n  input_df=True,\n  df_out=True\n  )\n\n\n\nBuild the pipeline\nWe are going to use sklearn’s DictVectorizer, which operates on numpy arrays/matrices. So to make it compatible with DataFrames, we’ll create a simple utility class to allow a DataFrame to be passed through the pipeline. Thanks to Chanseok for the dictifier code.\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n# Define Dictifier class to turn df into a dictionary as part of the pipeline\nclass Dictifier(BaseEstimator, TransformerMixin):\n  def fit(self, X, y=None):\n    return self\n  \n  def transform(self, X):\n    if type(X) == pd.core.frame.DataFrame:\n      return X.to_dict(\"records\")\n    else:\n      return pd.DataFrame(X).to_dict(\"records\")\n\nNow we build the pipeline. Notice how we use the FeatureUnion to bring the continuous and categorical features back together again at the start of the pipeline.\n\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction import DictVectorizer\nimport xgboost as xgb\n\nimputed_df = FeatureUnion([\n  ('num_imputer', numeric_imputor),\n  ('cat_imputer', categorical_imputor)    \n  ])\n  \nxgb_pipeline = Pipeline([\n  (\"featureunion\", imputed_df),\n  ('dictifier', Dictifier()),\n  ('dict_vectorizer', DictVectorizer(sort=False)),\n  (\"xgb\", xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n  ])\n\nC:\\Users\\A1849763\\Anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning:\n\npandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n\n\n\n\n\n3-Fold Cross Validation\nWe’ll use 3-fold cross-validation (instead of 10, or something greater) to minimize compute time.\n\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(xgb_pipeline, X, y, scoring=\"f1\", cv=3)\navg_f1 = np.mean(np.sqrt(np.abs(scores)))\nprint(\"Avg F1 Score:\", avg_f1)\n\nAvg F1 Score: 0.9999863537583441\n\n\n\n\nConclusions\nThe average F1 score is suspiciously high, so let’s not put much clout on the quality of the model. But it serves the purpose of demonstrating how to pass a ‘pandas’ DataFrame through a sklearn pipeline, preprocess mixed variable (continuous and categorical) data, and build an xgboost classifier.\nJust because it’s bugging me, here are a few things that may need to be improved in this model:\n\nThere is probably a high correlation between the target variable and some feature variables. We can check this quickly. Fill the NAs with zero and correlate it with the loan status (which is 0 and 1).\n\n\nnumeric_fillna_df = numeric_df.fillna(0)\nnumeric_fillna_df.corrwith(y)\n\nyear                         NaN\nloan_amount            -0.036825\nrate_of_interest       -0.958875\nInterest_rate_spread   -0.392977\nUpfront_charges        -0.431183\nterm                   -0.000675\nproperty_value         -0.273267\nincome                 -0.044620\nCredit_Score            0.004004\nLTV                    -0.267700\ndtir1                  -0.325613\ndtype: float64\n\n\nWe can see that rate_of_interest has a high inverse correlation with the target variable. However, I did try removing rate_of_interest and still ended up with an F1 score of 0.9999.\n\nFind a better way to impute the missing categorical. Chirag Goyal enumerates some options in this post. I suspect that building a model to predict missing values would be an option. Another simpler option would be to just randomly insert existing values. But, currently, with the imputer in this post, it is essentially treating ‘missing’ as a legit value."
  },
  {
    "objectID": "blog/posts/regex-preserve_currency_tokens.html",
    "href": "blog/posts/regex-preserve_currency_tokens.html",
    "title": "regex to Preserve Currency Tokens",
    "section": "",
    "text": "Introduction\nI’ve been working to collect a corpus of tax legislation, regulations, and court cases. At the core of my corpus is the United States Code Title 26 (USC26), otherwise known as the Internal Revenue Code or the U.S. Tax Code. I’m using the corpus to train a tax-specific word embedding. Word embeddings capture similarity semantics of tokens (words, or multi-word phrases) by encoding them into a n-dimensional space. Similar tokens are embedded into the n-dimensional space in close proximity.\nSince currency values may have important semantic meaning in the USC–for instance, tax bracket boundaries–I want to preserve them so the tokenizer does not break them apart. To do this, I want to replace spaces, commas, decimals, and dollar signs with underscores. Here are some examples:\n\nExamples of Currency Values\n\n\nOriginal\nPreserved\n\n\n\n\n$172,175\n172_175_usd\n\n\n$2.5 million\n2_5_million_usd\n\n\n$56,750.25\n56_750_25_usd\n\n\n\n\n\nImplementation\nThe approach I took was to first match the different currency formats and then pass the match to a helper function that would replace spaces, commas, decimals, and dollar signs with underscores.\nHere is the pattern I created to match currency tokens:\n\npattern = r'\\$\\d{0,3}(\\,\\d{3}){0,4}(\\.\\d{1,2})?( (million|billion))?'\n\n\n\\$ matches a dollar sign.\n\\d{0,3} The number after the dollar sign and before a comma or decimal boundary. Looking for 0 to 3 digits allows for these patterns: $.75, $125,000, etc.\n(\\,\\d{3}){0,4}(\\.\\d{1,2})? matches repeated comma boundaries (if they exist) and two-decimal places for cents (if they exist). More specifically:\n\n(\\,\\d{3}) matches “,xxx”. With the addition of {0,4} it matches “,xxx” repeatedly–up to trillions (which is probably overkill for the USC26 because most large currency values have “million” or “billion” text suffixes).\n(\\.\\d{1,2})? matches an optional cents.\n\n( (million|billion))? just checks for a text suffix (the ? at the end makes it optional.)\n\nNext, here is a simple helper function to replace spaces, commas, decimals, and dollar signs with underscores and tack on “_usd” at the end. Python’s string replace() method is faster than the regex sub(), so I went with replace().\n\nimport re\n\ndef replace_currency_parts(match):\n    text = match.group(0).replace(\" \", \"_\").replace(\".\", \"_\").replace(',', '_')\n    if (text[0] == '$'):\n        text = text[1:] + \"_usd\"\n    return text\n\nNow I need a test string.\n\ntest_string = \"I made $755.34 billion this year, $5.34 million last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45 in case that's a more realistic salary in my life.\"\n\nThen I compile the regex and replace matches. Notice that the second argument of sub() can take a method that returns a string. I leverage this to call the helper function.\n\ncompiled_pattern = re.compile(pattern)\ncompiled_pattern.sub(replace_currency_parts, test_string)\n\n\"I made 755_34_billion_usd this year, 5_34_million_usd last year, but I also want to match 125_234_34_usd and 1_342_40_usd and 45_09_usd and 45_usd in case that's a more realistic salary in my life.\"\n\n\nHere is the full Python implementation.\n\nimport time\nimport timeit\n\npattern = r'\\$\\d{0,3}(\\,\\d{3}){0,4}(\\.\\d{1,2})?( (million|billion))?'\n\ndef replace_currency_parts(match):\n    text = match.group(0).replace(\" \", \"_\").replace(\".\", \"_\").replace(',', '_')\n    if (text[0] == '$'):\n        text = text[1:] + \"_usd\"\n    return text\n\ntest_string = \"I made $355.34 million this year, $435.34 billion last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45.\"\n\ncompiled_pattern = re.compile(pattern)\ncompiled_pattern.sub(replace_currency_parts, test_string)\n\n\n\nR Implementation\nI was curious if python was that much faster than R. So, here is an R implementation. Like Python’s sub(), the str_replace_all function can take a helper function.\n\nlibrary(stringr)\n\npattern <- '\\\\$\\\\d{0,3}(\\\\,\\\\d{3}){0,4}(\\\\.\\\\d{1,2})?( (million|billion))?'\n\nreplace_currency_parts <- function(match) {\n  \n  text <- match %>% \n    str_replace_all(\" \", \"_\") %>% \n    str_replace_all(\"\\\\.\", \"_\") %>% \n    str_replace_all(\"\\\\,\", \"_\")\n    \n  if (str_sub(text, 1, 1) == \"$\"){\n    text <- str_c(str_sub(text, 2), \"_usd\")\n  }\n    \n  return(text)\n}\n\ntest_string <-  \"I made $355.34 million this year, $435.34 billion last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45.\"\n\nstr_replace_all(test_string, pattern, replace_currency_parts)\n\n[1] \"I made 355_34_million_usd this year, 435_34_billion_usd last year, but I also want to match 125_234_34_usd and 1_342_40_usd and 45_09_usd and 45_usd.\"\n\n\n\n\nWhich is faster?\nSo, which is faster?\nI compare the Python and R implementations by taking the average of 1000 executions of the code. Since the {stringr} package in R is higher level–there’s no option to compile the regex ahead of time and keep it out of the loop–I placed the Python regex compile code inside the loop to make a more fair comparison. In both cases, the units are milliseconds. NOTE: The python time() method returns seconds, so I convert.\n\nfrom time import time\n\nstart_ms = int(round(time() * 1000))\nfor i in range(1000):\n  compiled_pattern = re.compile(pattern)\n  str = compiled_pattern.sub(replace_currency_parts, test_string)\nend_ms = int(round(time() * 1000))\n\nprint(\"elapsed ms = \", (end_ms-start_ms)/1000)\n\nelapsed ms =  0.024\n\n\n\nlibrary(microbenchmark)\n\nmicrobenchmark::microbenchmark(str_replace_all(test_string, pattern, replace_currency_parts), times = 1000)\n\nUnit: milliseconds\n                                                          expr    min     lq\n str_replace_all(test_string, pattern, replace_currency_parts) 1.9911 2.0367\n     mean median     uq     max neval\n 2.100773 2.0643 2.0952 10.0281  1000\n\n\nI don’t know what overhead is included in the {stringr} package, but it’s about two orders of magnitude slower than Python. I suspect it is because the Python replace() string method is quite speedy."
  },
  {
    "objectID": "blog/dataprep/regex-preserve_currency_tokens.html",
    "href": "blog/dataprep/regex-preserve_currency_tokens.html",
    "title": "regex to Preserve Currency Tokens",
    "section": "",
    "text": "Introduction\nI’ve been working to collect a corpus of tax legislation, regulations, and court cases. At the core of my corpus is the United States Code Title 26 (USC26), otherwise known as the Internal Revenue Code or the U.S. Tax Code. I’m using the corpus to train a tax-specific word embedding. Word embeddings capture similarity semantics of tokens (words, or multi-word phrases) by encoding them into an n-dimensional space. Similar tokens are embedded into the n-dimensional space in close proximity.\nSince currency values may have important semantic meaning in the USC–for instance, tax bracket boundaries–I want to preserve them so the tokenizer does not break them apart. To do this, I want to replace spaces, commas, decimals, and dollar signs with underscores. Here are some examples:\n\nExamples of Currency Values\n\n\nOriginal\nPreserved\n\n\n\n\n$172,175\n172_175_usd\n\n\n$2.5 million\n2_5_million_usd\n\n\n$56,750.25\n56_750_25_usd\n\n\n\n\n\nImplementation\nThe approach I took was to first match the different currency formats and then pass the match to a helper function that would replace spaces, commas, decimals, and dollar signs with underscores.\nHere is the pattern I created to match currency tokens:\n\npattern = r'\\$\\d{0,3}(\\,\\d{3}){0,4}(\\.\\d{1,2})?( (million|billion))?'\n\n\n\\$ matches a dollar sign.\n\\d{0,3} The number after the dollar sign and before a comma or decimal boundary. Looking for 0 to 3 digits allows for these patterns: $.75, $125,000, etc.\n(\\,\\d{3}){0,4}(\\.\\d{1,2})? matches repeated comma boundaries (if they exist) and two-decimal places for cents (if they exist). More specifically:\n\n(\\,\\d{3}) matches “,xxx”. With the addition of {0,4} it matches “,xxx” repeatedly–up to trillions (which is probably overkill for the USC26 because most large currency values have “million” or “billion” text suffixes).\n(\\.\\d{1,2})? matches an optional cents.\n\n( (million|billion))? just checks for a text suffix (the ? at the end makes it optional.)\n\nNext, here is a simple helper function to replace spaces, commas, decimals, and dollar signs with underscores and tack on “_usd” at the end. Python’s string replace() method is faster than the regex sub(), so I went with replace().\n\nimport re\n\ndef replace_currency_parts(match):\n    text = match.group(0).replace(\" \", \"_\").replace(\".\", \"_\").replace(',', '_')\n    if (text[0] == '$'):\n        text = text[1:] + \"_usd\"\n    return text\n\nNow I need a test string.\n\ntest_string = \"I made $755.34 billion this year, $5.34 million last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45 in case that's a more realistic salary in my life.\"\n\nThen I compile the regex and replace matches. Notice that the second argument of sub() can take a method that returns a string. I leverage this to call the helper function.\n\ncompiled_pattern = re.compile(pattern)\ncompiled_pattern.sub(replace_currency_parts, test_string)\n\n\"I made 755_34_billion_usd this year, 5_34_million_usd last year, but I also want to match 125_234_34_usd and 1_342_40_usd and 45_09_usd and 45_usd in case that's a more realistic salary in my life.\"\n\n\nHere is the full Python implementation.\n\nimport time\nimport timeit\n\npattern = r'\\$\\d{0,3}(\\,\\d{3}){0,4}(\\.\\d{1,2})?( (million|billion))?'\n\ndef replace_currency_parts(match):\n    text = match.group(0).replace(\" \", \"_\").replace(\".\", \"_\").replace(',', '_')\n    if (text[0] == '$'):\n        text = text[1:] + \"_usd\"\n    return text\n\ntest_string = \"I made $355.34 million this year, $435.34 billion last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45.\"\n\ncompiled_pattern = re.compile(pattern)\ncompiled_pattern.sub(replace_currency_parts, test_string)\n\n\n\nR Implementation\nI was curious if python was that much faster than R. So, here is an R implementation. Like Python’s sub(), the str_replace_all function can take a helper function.\n\nlibrary(stringr)\n\npattern <- '\\\\$\\\\d{0,3}(\\\\,\\\\d{3}){0,4}(\\\\.\\\\d{1,2})?( (million|billion))?'\n\nreplace_currency_parts <- function(match) {\n  \n  text <- match %>% \n    str_replace_all(\" \", \"_\") %>% \n    str_replace_all(\"\\\\.\", \"_\") %>% \n    str_replace_all(\"\\\\,\", \"_\")\n    \n  if (str_sub(text, 1, 1) == \"$\"){\n    text <- str_c(str_sub(text, 2), \"_usd\")\n  }\n    \n  return(text)\n}\n\ntest_string <-  \"I made $355.34 million this year, $435.34 billion last year, but I also want to match $125,234.34 and $1,342.40 and $45.09 and $45.\"\n\nstr_replace_all(test_string, pattern, replace_currency_parts)\n\n[1] \"I made 355_34_million_usd this year, 435_34_billion_usd last year, but I also want to match 125_234_34_usd and 1_342_40_usd and 45_09_usd and 45_usd.\"\n\n\n\n\nWhich is faster?\nSo, which is faster?\nI compare the Python and R implementations by taking the average of 1000 executions of the code. Since the {stringr} package in R is higher level–there’s no option to compile the regex ahead of time and keep it out of the loop–I placed the Python regex compile code inside the loop to make a more fair comparison. In both cases, the units are milliseconds. NOTE: The python time() method returns seconds, so I convert.\n\nfrom time import time\n\nstart_ms = int(round(time() * 1000))\nfor i in range(1000):\n  compiled_pattern = re.compile(pattern)\n  str = compiled_pattern.sub(replace_currency_parts, test_string)\nend_ms = int(round(time() * 1000))\n\nprint(\"elapsed ms = \", (end_ms-start_ms)/1000)\n\nelapsed ms =  0.031\n\n\n\nlibrary(microbenchmark)\n\nmicrobenchmark::microbenchmark(str_replace_all(test_string, pattern, replace_currency_parts), times = 1000)\n\nUnit: milliseconds\n                                                          expr    min     lq\n str_replace_all(test_string, pattern, replace_currency_parts) 4.1608 4.5206\n     mean median     uq     max neval\n 5.057107 4.7471 5.2982 11.7094  1000\n\n\nI don’t know what overhead is included in the {stringr} package, but it’s about two orders of magnitude slower than Python. I suspect it is because the Python replace() string method is quite speedy."
  },
  {
    "objectID": "blog/machinelearn/using-xgboost-and-sklearn-to-predict-loan-default.html",
    "href": "blog/machinelearn/using-xgboost-and-sklearn-to-predict-loan-default.html",
    "title": "Using xgboost and sklearn to Predict Loan Default",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd \n\n\nIntroduction\nI wanted to combine xgboost with sklearn pipelines to process a pandas DataFrame. Special thanks to Kaggle user M Yasser H for supplying the Loan Default Dataset.\n\n\nLoad the data\n\n# Load the data\nloan_df = pd.read_csv(\"data/Loan_Default.csv\")\n\n\n\nCreate labels and features\nThe loan status (whether or not the customer defaulted on the loan) is the target variable. We’ll extract that out as our labels. The other columns (minus the ID) will serve as our features. And we’ll take a peek at our features.\n\n# Split out labels and features, encode labels as integers\ny = loan_df['Status']\n\nX = loan_df.loc[:,~loan_df.columns.isin(['ID','Status'])]\n\n\n\nSimple data exploration\nTake a peek at our feature variables.\n\nX.head()\n\n\n\n\n\n  \n    \n      \n      year\n      loan_limit\n      Gender\n      approv_in_adv\n      loan_type\n      loan_purpose\n      Credit_Worthiness\n      open_credit\n      business_or_commercial\n      loan_amount\n      ...\n      income\n      credit_type\n      Credit_Score\n      co-applicant_credit_type\n      age\n      submission_of_application\n      LTV\n      Region\n      Security_Type\n      dtir1\n    \n  \n  \n    \n      0\n      2019\n      cf\n      Sex Not Available\n      nopre\n      type1\n      p1\n      l1\n      nopc\n      nob/c\n      116500\n      ...\n      1740.0\n      EXP\n      758\n      CIB\n      25-34\n      to_inst\n      98.728814\n      south\n      direct\n      45.0\n    \n    \n      1\n      2019\n      cf\n      Male\n      nopre\n      type2\n      p1\n      l1\n      nopc\n      b/c\n      206500\n      ...\n      4980.0\n      EQUI\n      552\n      EXP\n      55-64\n      to_inst\n      NaN\n      North\n      direct\n      NaN\n    \n    \n      2\n      2019\n      cf\n      Male\n      pre\n      type1\n      p1\n      l1\n      nopc\n      nob/c\n      406500\n      ...\n      9480.0\n      EXP\n      834\n      CIB\n      35-44\n      to_inst\n      80.019685\n      south\n      direct\n      46.0\n    \n    \n      3\n      2019\n      cf\n      Male\n      nopre\n      type1\n      p4\n      l1\n      nopc\n      nob/c\n      456500\n      ...\n      11880.0\n      EXP\n      587\n      CIB\n      45-54\n      not_inst\n      69.376900\n      North\n      direct\n      42.0\n    \n    \n      4\n      2019\n      cf\n      Joint\n      pre\n      type1\n      p1\n      l1\n      nopc\n      nob/c\n      696500\n      ...\n      10440.0\n      CRIF\n      602\n      EXP\n      25-34\n      not_inst\n      91.886544\n      North\n      direct\n      39.0\n    \n  \n\n5 rows × 32 columns\n\n\n\nNotice there is a mix of categorical and continuous variables.\nLet’s check if there are any missing values.\n\nX.isnull().sum()\n\nyear                             0\nloan_limit                    3344\nGender                           0\napprov_in_adv                  908\nloan_type                        0\nloan_purpose                   134\nCredit_Worthiness                0\nopen_credit                      0\nbusiness_or_commercial           0\nloan_amount                      0\nrate_of_interest             36439\nInterest_rate_spread         36639\nUpfront_charges              39642\nterm                            41\nNeg_ammortization              121\ninterest_only                    0\nlump_sum_payment                 0\nproperty_value               15098\nconstruction_type                0\noccupancy_type                   0\nSecured_by                       0\ntotal_units                      0\nincome                        9150\ncredit_type                      0\nCredit_Score                     0\nco-applicant_credit_type         0\nage                            200\nsubmission_of_application      200\nLTV                          15098\nRegion                           0\nSecurity_Type                    0\ndtir1                        24121\ndtype: int64\n\n\n\n\nPreprocessing\nSince we have a mix of continuous and categorical variables, we’ll set up an imputer for each type of variable. So, we are going to separate the continuous and the categorical variables into separate DataFrames.\nFor the continuous variables, we’ll impute the median.\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.impute import SimpleImputer\n\n# extract numeric columns\nnumeric_mask = (X.dtypes != object)\nnumeric_columns = X.columns[numeric_mask].tolist()\nnumeric_df = X[numeric_columns]\n\n# create \"imputer\", just going to fill missing values with \"missing\"\nnumeric_imputor = DataFrameMapper(\n  [([numeric_feature], SimpleImputer(strategy='median')) for numeric_feature in numeric_df],\n  input_df=True,\n  df_out=True\n  )\n\nFor the categorical variables, we’ll impute the value ‘missing’.\n\n# extract categorical features\ncategorical_mask = (X.dtypes == object)\ncategorical_columns = X.columns[categorical_mask].tolist()\ncategorical_df = X[categorical_columns]\n\ncategorical_imputor = DataFrameMapper(\n  [([categorical_feature], SimpleImputer(strategy='constant', fill_value = \"missing\")) for categorical_feature in categorical_df],\n  input_df=True,\n  df_out=True\n  )\n\n\n\nBuild the pipeline\nWe are going to use sklearn’s DictVectorizer, which operates on numpy arrays/matrices. So to make it compatible with DataFrames, we’ll create a simple utility class to allow a DataFrame to be passed through the pipeline. Thanks to Chanseok for the dictifier code.\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n# Define Dictifier class to turn df into a dictionary as part of the pipeline\nclass Dictifier(BaseEstimator, TransformerMixin):\n  def fit(self, X, y=None):\n    return self\n  \n  def transform(self, X):\n    if type(X) == pd.core.frame.DataFrame:\n      return X.to_dict(\"records\")\n    else:\n      return pd.DataFrame(X).to_dict(\"records\")\n\nNow we build the pipeline. Notice how we use the FeatureUnion to bring the continuous and categorical features back together again at the start of the pipeline.\n\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction import DictVectorizer\nimport xgboost as xgb\n\nimputed_df = FeatureUnion([\n  ('num_imputer', numeric_imputor),\n  ('cat_imputer', categorical_imputor)    \n  ])\n  \nxgb_pipeline = Pipeline([\n  (\"featureunion\", imputed_df),\n  ('dictifier', Dictifier()),\n  ('dict_vectorizer', DictVectorizer(sort=False)),\n  (\"xgb\", xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n  ])\n\n\n\n3-Fold Cross Validation\nWe’ll use 3-fold cross-validation (instead of 10, or something greater) to minimize compute time.\n\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(xgb_pipeline, X, y, scoring=\"f1\", cv=3)\navg_f1 = np.mean(np.sqrt(np.abs(scores)))\nprint(\"Avg F1 Score:\", avg_f1)\n\nAvg F1 Score: 0.9999863537583441\n\n\n\n\nConclusions\nThe average F1 score is suspiciously high, so let’s not put much clout on the quality of the model. But it serves the purpose of demonstrating how to pass a ‘pandas’ DataFrame through a sklearn pipeline, preprocess mixed variable (continuous and categorical) data, and build an xgboost classifier.\nJust because it’s bugging me, here are a few things that may need to be improved in this model:\n\nThere is probably a high correlation between the target variable and some feature variables. We can check this quickly. Fill the NAs with zero and correlate it with the loan status (which is 0 and 1).\n\n\nnumeric_fillna_df = numeric_df.fillna(0)\nnumeric_fillna_df.corrwith(y)\n\nyear                         NaN\nloan_amount            -0.036825\nrate_of_interest       -0.958875\nInterest_rate_spread   -0.392977\nUpfront_charges        -0.431183\nterm                   -0.000675\nproperty_value         -0.273267\nincome                 -0.044620\nCredit_Score            0.004004\nLTV                    -0.267700\ndtir1                  -0.325613\ndtype: float64\n\n\nWe can see that rate_of_interest has a high inverse correlation with the target variable. However, I did try removing rate_of_interest and still ended up with an F1 score of 0.9999.\n\nFind a better way to impute the missing categorical. Chirag Goyal enumerates some options in this post. I suspect that building a model to predict missing values would be an option. Another simpler option would be to just randomly insert existing values. But, currently, with the imputer in this post, it is essentially treating ‘missing’ as a legit value."
  },
  {
    "objectID": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html",
    "href": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "",
    "text": "One way to perform dimensionality reduction is through feature selection. In this post, we’ll explore how to create a low-variance feature mask (or filter). We’ll cover both a manual approach with dplyr functions and a more automated, production approach with recipes functions. Enjoy!\n\n\nVariance is important in feature selection because of a concept called information gain. Information gain is what we know about one (usually unknown) variable because we can observe another known variable. In supervised learning, we use information from predictor variables to learn something about the target variable.\nTo make this concrete, imagine we want to estimate loan applicants’ creditworthiness. Though we don’t have their credit scores, we do have their monthly income, age, and number of outstanding loans. If every applicant in our data set has three outstanding loans – that is, the number of outstanding loans didn’t vary – then “outstanding loans” does not differentiate loan applicants and, therefore, does not provide any information about the applicants that we can use to estimate their creditworthiness. Therefore, we’d say that number of outstanding loans provides no information gain about creditworthiness.\nWe can remove features with little to no variance because they are not informative. Consider them useless fluff."
  },
  {
    "objectID": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#load-data-with-categorical-variables",
    "href": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#load-data-with-categorical-variables",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Load data with categorical variables",
    "text": "Load data with categorical variables\nTo demonstrate the recipes approach, we’ll load all the features, so we have both continuous and categorical variables.\n\ncredit_df <- \n  read_csv(\"data/credit_data.csv\")\n\nTo make this example interesting, we’ll insert a couple of low-variance features – num_credit_card and num_credit_inquiries.\n\ncredit_df <- credit_df %>% \n  mutate(\n    num_credit_card_rand = runif(n()),\n    num_credit_inquiries_rand = runif(n()),\n    num_credit_card = if_else(\n      num_credit_card_rand < .95, 5, num_credit_card),\n    num_credit_inquiries = if_else(\n      num_credit_inquiries_rand < .95, 3, num_credit_inquiries)\n  ) %>% \n  select(-num_credit_card_rand, -num_credit_inquiries_rand)"
  },
  {
    "objectID": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#inject-some-low-variance-features",
    "href": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#inject-some-low-variance-features",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Inject some low variance features",
    "text": "Inject some low variance features\nTo make this example interesting, we’ll insert a couple of low-variance features – num_credit_card and num_credit_inquiries.\n\ncredit_df <- credit_df %>% \n  mutate(\n    num_credit_card_rand = runif(n()),\n    num_credit_inquiries_rand = runif(n()),\n    num_credit_card = if_else(num_credit_card_rand < .95, 5, num_credit_card),\n    num_credit_inquiries = if_else(num_credit_inquiries_rand < .95, 3, num_credit_inquiries)\n  ) %>% \n  select(-num_credit_card_rand, -num_credit_inquiries_rand)"
  },
  {
    "objectID": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#define-a-recipe-object",
    "href": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#define-a-recipe-object",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Define a recipe object",
    "text": "Define a recipe object\nThen we define a recipe object. Notice the first parameter is a formula. We define credit_score as the target variable and all other features as predictor variables.\nWe add the step_zv() step first. No-variance features will cause problems when we normalize the data with step_scale(). We apply the no-variance step to all predictors and the scale step to only the numeric predictors. Then, we apply step_nzv() to remove low-variance features. prep() “fits” the recipe to the data.\n\nlibrary(recipes) \n\nlow_variance_recipe <- recipe(credit_score ~ ., data = credit_df) %>%\n  step_zv(all_predictors()) %>%\n  step_scale(all_numeric_predictors()) %>%\n  step_nzv(all_predictors()) %>%\n  prep()\n\nWe can use tidy() to peek into the recipe and see the effect it will have on the trained data set it was trained on. Here we look at the third step of the recipe – step_nzv(). We can see that it will remove our two low-variance features – num_credit_card and num_credit_inquiries.\n\ntidy(low_variance_recipe, number = 3)\n\n# A tibble: 2 × 2\n  terms                id       \n  <chr>                <chr>    \n1 num_credit_card      nzv_5xxFQ\n2 num_credit_inquiries nzv_5xxFQ"
  },
  {
    "objectID": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#apply-the-recipe-to-credit_df",
    "href": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#apply-the-recipe-to-credit_df",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Apply the recipe to credit_df",
    "text": "Apply the recipe to credit_df\nIn recipes to apply a trained recipe to a data set, we can use bake(). The new_data parameter allows us to specify the data set “bake” the recipe with. If we pass NULL, it will bake the same data that the recipe was trained on.\n\nfiltered_credit_df <- low_variance_recipe %>% bake(new_data = NULL)\n\nnames(filtered_credit_df)\n\n [1] \"month\"                    \"age\"                     \n [3] \"occupation\"               \"annual_income\"           \n [5] \"monthly_inhand_salary\"    \"num_bank_accounts\"       \n [7] \"interest_rate\"            \"num_of_loan\"             \n [9] \"delay_from_due_date\"      \"num_of_delayed_payment\"  \n[11] \"changed_credit_limit\"     \"outstanding_debt\"        \n[13] \"credit_utilization_ratio\" \"payment_of_min_amount\"   \n[15] \"total_emi_per_month\"      \"amount_invested_monthly\" \n[17] \"payment_behaviour\"        \"monthly_balance\"         \n[19] \"credit_history_months\"    \"credit_score\"            \n\n\nIf we compare the names in the original credit_df to the names in the filtered_credit_df, we can see that num_credit_card and num_credit_inquiries were removed.\n\nsetdiff(names(credit_df), names(filtered_credit_df))\n\n[1] \"num_credit_card\"      \"num_credit_inquiries\""
  },
  {
    "objectID": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#setup",
    "href": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#setup",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Setup",
    "text": "Setup\nFor this example, we’ll use a credit score classification data set from Kaggle, provided by Rohan Paris. The data set is large, so I randomly sampled 20% of it. I also did a little data cleaning. As you’ll see, to make this exercise interesting, we’ll add a few low-variance features to demonstrate feature removal.\nYou can download the cleaned data set here.\nSince variance is conceptually simpler with continuous variables, let’s only load the continuous variables into credit_df.\n\nlibrary(tidyverse)\nlibrary(knitr)\n\ncredit_df <- \n  read_csv(\"data/credit_data.csv\") %>% \n  select_if(is.numeric)\n\nHere’s a peek at the data.\n\nkable(credit_df %>% head(5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nannual_income\nmonthly_inhand_salary\nnum_bank_accounts\nnum_credit_card\ninterest_rate\nnum_of_loan\ndelay_from_due_date\nnum_of_delayed_payment\nchanged_credit_limit\nnum_credit_inquiries\noutstanding_debt\ncredit_utilization_ratio\ntotal_emi_per_month\namount_invested_monthly\nmonthly_balance\ncredit_history_months\n\n\n\n\n41\n16176.83\n1585.070\n8\n3\n10\n3\n17\n14\n0.56\n2445\n1200.70\n29.94733\n21.96219\n38.32601\n358.2188\n241\n\n\n36\n82383.04\n6661.253\n3\n5\n8\n4\n17\n14\n1.71\n2\n1218.57\n33.38963\n162.10896\n123.97997\n630.0364\n392\n\n\n44\n28805.34\n2309.445\n8\n3\n5\n2\n13\n19\n7.02\n0\n796.45\n26.83209\n47.19512\n139.90769\n303.8417\n385\n\n\n28\n45412.95\n3520.412\n8\n6\n30\n6\n28\n21\n23.07\n6\n4601.39\n23.41958\n113.69155\n199.56341\n318.7863\n55\n\n\n45\n17296.38\n1480.365\n6\n10\n30\n5\n21\n17\n17.34\n7\n4624.73\n38.39057\n49.36071\n78.16123\n280.5146\n92"
  },
  {
    "objectID": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#calculate-feature-variances",
    "href": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#calculate-feature-variances",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Calculate feature variances",
    "text": "Calculate feature variances\nTo begin, let’s calculate the variance of each column. With dplyr, we’ll use across() to apply var() to all columns with the everything() selector. Notice that we scale() the data before passing it to var(). It is important to normalize the data so the features are comparable with each other. Unnormalized, num_credit_card and monthly income, have very different variances. To compare their influence on creditworthiness in a fair manner, we normalize them.\nWe use tidyr’s pivot_longer() to pivot the scaled variances to columns. We’ll sort them from largest to smallest.\n\ncredit_variances <- credit_df %>% \n  summarize(\n    across(\n        everything(), \n        ~ var(scale(., center = FALSE)), \n        na.rm = TRUE)) %>% \n  pivot_longer(\n    everything(), \n    names_to = \"feature\", \n    values_to = \"variance\") %>% \n  arrange(desc(variance)) \n\nkable(credit_variances)\n\n\n\n\nfeature\nvariance\n\n\n\n\nnum_of_loan\n0.98558800\n\n\ninterest_rate\n0.98258481\n\n\nnum_of_delayed_payment\n0.98150878\n\n\nnum_credit_inquiries\n0.97843457\n\n\nnum_bank_accounts\n0.97841843\n\n\ntotal_emi_per_month\n0.97569764\n\n\nannual_income\n0.97397017\n\n\nnum_credit_card\n0.97044729\n\n\namount_invested_monthly\n0.90345646\n\n\noutstanding_debt\n0.41753915\n\n\nmonthly_inhand_salary\n0.35255863\n\n\ndelay_from_due_date\n0.33223435\n\n\nchanged_credit_limit\n0.30855481\n\n\nmonthly_balance\n0.22081631\n\n\ncredit_history_months\n0.15974632\n\n\nage\n0.07874258\n\n\ncredit_utilization_ratio\n0.02527138"
  },
  {
    "objectID": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#set-variance-threshold-and-create-a-mask",
    "href": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#set-variance-threshold-and-create-a-mask",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Set variance threshold and create a mask",
    "text": "Set variance threshold and create a mask\nWe can scan down the variances and identify a natural cut-off between amount_invested_monthly and outstanding_debt, however, that would remove too many features. The next cutoff between credit_history_month and age seems more appropriate. So, we can create a variance filter with a threshold of 0.1.\nWe use pull() to get an array of feature names that we can use as a mask.\n\nlow_var_filter <- credit_variances %>% \n  filter(variance < 0.1) %>% \n  pull(feature)\n\nlow_var_filter\n\n[1] \"age\"                      \"credit_utilization_ratio\""
  },
  {
    "objectID": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#apply-the-mask",
    "href": "blog/dataprep/simple-low-variance-feature-selection-mask-in-r.html#apply-the-mask",
    "title": "Simple Feature Selection Using a Low-to-No Variance Mask",
    "section": "Apply the mask",
    "text": "Apply the mask\nWe then apply the mask to the data frame. Notice that it removes ‘age’ and credit_utilization_ratio.\n\nfiltered_credit_df <- credit_df %>% \n  select(-all_of(low_var_filter))\n\nkable(filtered_credit_df %>% head(5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nannual_income\nmonthly_inhand_salary\nnum_bank_accounts\nnum_credit_card\ninterest_rate\nnum_of_loan\ndelay_from_due_date\nnum_of_delayed_payment\nchanged_credit_limit\nnum_credit_inquiries\noutstanding_debt\ntotal_emi_per_month\namount_invested_monthly\nmonthly_balance\ncredit_history_months\n\n\n\n\n16176.83\n1585.070\n8\n3\n10\n3\n17\n14\n0.56\n2445\n1200.70\n21.96219\n38.32601\n358.2188\n241\n\n\n82383.04\n6661.253\n3\n5\n8\n4\n17\n14\n1.71\n2\n1218.57\n162.10896\n123.97997\n630.0364\n392\n\n\n28805.34\n2309.445\n8\n3\n5\n2\n13\n19\n7.02\n0\n796.45\n47.19512\n139.90769\n303.8417\n385\n\n\n45412.95\n3520.412\n8\n6\n30\n6\n28\n21\n23.07\n6\n4601.39\n113.69155\n199.56341\n318.7863\n55\n\n\n17296.38\n1480.365\n6\n10\n30\n5\n21\n17\n17.34\n7\n4624.73\n49.36071\n78.16123\n280.5146\n92"
  },
  {
    "objectID": "blog/nlp/gc_topic_model_best_fit.html#introduction",
    "href": "blog/nlp/gc_topic_model_best_fit.html#introduction",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "blog/nlp/gc_topic_model_best_fit.html#preparing-the-data",
    "href": "blog/nlp/gc_topic_model_best_fit.html#preparing-the-data",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Preparing the data",
    "text": "Preparing the data\nI used the tidytext package1 to tokenize the General Conference (GC) talks into unigrams. I removed common stopwords and did basic data cleaning. I then used cast_dfm() to convert the tidy text data frame to a document-feature matrix (DFM) compatible with quanteda. This blog post starts with this DFM of the GC talks.\nquanteda does not implement topic models, so I’ll use the Latent Dirichlet Allocation (LDA) implementation provided by the seededlda package to create the topic model."
  },
  {
    "objectID": "blog/nlp/gc_topic_model_best_fit.html#loading-the-data",
    "href": "blog/nlp/gc_topic_model_best_fit.html#loading-the-data",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Loading the data",
    "text": "Loading the data\nI saved the DFM in an RDS format for quick retrieval. Let’s load the data and take a look at its dimensions.\n\nlibrary(tidyverse)\nlibrary(quanteda)\nunigram_dfm <- read_rds(\"data/unigram_dfm.rds\")\ndim(unigram_dfm)\n\n[1]  3881 16336\n\n\nThe matrix represents 3,881 documents (GC talks) and 16,336 words (unigrams). Keep in mind that many stopwords (e.g., the, and, am, etc.) were removed. The hope is that the remaining words are significant and salient."
  },
  {
    "objectID": "blog/nlp/gc_topic_model_best_fit.html#the-topic-model",
    "href": "blog/nlp/gc_topic_model_best_fit.html#the-topic-model",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "The topic model",
    "text": "The topic model\nLike clustering algorithms, LDA requires that we specify the number of topics to fit. With close to 4k talks and 16k+ words, it wasn’t clear to me how many topics I should fit. To discover this, I leveraged the divergence metric of the topic model. seededlda, in its divergence() function, implements the Kullback-Leibler (KL) divergence, which is frequently used to measure the dissimilarities between word distributions (i.e., topics) 2.\nIn a nutshell, the logic of topic divergence is like this:\n\nTopics consist of individual words. For example,\n\nFamily: children, family, home, parents, love, god, husband, wife\nMissionary Work: mission, missionary, serve, gospel, elder, lord\nSavior: love, christ, jesus, savior, father, heart\n\nThe words that make up topics can overlap, meaning that the words can appear in several topics. For instance, love appears in both the Savior and Family topics.\nWhen we minimize the overlap, or maximize the divergence, of topics; then we have some assurance that we have the most distinct and useful topics.\n\nTo find the optimal number of topics, I fit topic models with 2 to 52 topics.\n\nNote: There was a bit of trial and error to arrive at that range.\n\nThen I plotted their divergence scores to see where they maxed out.\nSince fitting LDA models is computationally expensive, I used the furrr package – the parallelized version of purrr – on my high-powered server to fit all those models.\nThen I combined the divergence score with each topic model into a data frame, so I could plot them.\n\nlibrary(seededlda)\nlibrary(furrr)\n\n# create a vector for number of topics to fit\nn <- seq(2, 52, by = 2)\n\n# helper function that fits the LDA model and computes the divergence\n# this is to parallelize the code with the 'furrr' package\nget_div_score <- function(dfm, k) {\n  lda_fit <- textmodel_lda(dfm, k)\n  return(divergence(lda_fit))\n}\n\n# setup four threads\nplan(multisession, workers = 4)\n\n# fit models in parallel\ndiv_scores <- n %>% \n  future_map_dbl(\n    ~get_div_score(unigram_dfm, k = .x),\n    furrr_options(seed = TRUE))\n\n# assemble a df with number of topics and divergence scores\ndiv_score_df <- tibble(\n  num_topics = n,\n  div_score = div_scores\n)\n\n\n\n\n\nFinding the maximum divergence – the quantitative part\nHere’s the code to create the number of topics vs. divergence plot.\n\n# plot topic number vs divergence score\ndiv_score_df %>% \n  ggplot(aes(x = num_topics, y = div_score)) +\n  geom_point() +\n  ylab(\"Divergence Score\") +\n  xlab(\"Number of Topics\") +\n  geom_hline(yintercept = max(div_score_df$div_score), \n             color = \"blue\", \n             linetype = \"dashed\") +\n  annotate(\"text\", \n           x=30, \n           y=max(div_score_df$div_score)+0.01, \n           label=\"0.436\",\n           color = \"blue\") +\n  ggtitle(\"Number of Topics vs Divergence\")\n\n\n\n\nIn the end, it was easier to just view the top three results in a table.\n\ndiv_score_df %>% \n  arrange(desc(div_score)) %>% \n  head(5)\n\n# A tibble: 5 × 2\n  num_topics div_score\n       <dbl>     <dbl>\n1         30     0.436\n2         32     0.435\n3         28     0.434\n4         24     0.433\n5         26     0.433\n\n\n\n\nInterpreting the topics – the qualitative part\nWhile the 30-topic model has the highest divergence, maximal divergence does not necessarily mean that that number of topics is maximally meaningful. So I took the models with the top three divergence scores (32-topic, 30-topic, and 28-topics) and explored the quality of the topics.\nI created these models in parallel on my server. Here’s the code:\n\nn <- c(28, 30, 32)\n\nplan(multisession, workers = 3)\nlda_fits <- n %>% \n  future_map(\n    ~textmodel_lda(unigram_dfm, k = .x),\n    furrr_options(seed = TRUE))\n\nAfter the 28-, 30-, and 32-topics models were fit, I created labels for each topic based on the words that the topic was composed of to evaluate the topic quality. Here I’ll demonstrate this process with the 30- and 32-topic models.\nI extracted the words per topic with the terms() function and formed them into a tibble for ease of reading. Then I proceeded to subjectively interpret the topics based on the top 10 words in each topic. I don’t believe there is a way to avoid this. Notice that I updated the column names with meaningful labels.\nIt is expected that there will be some noisy topics. If the topic wasn’t clear to me, I labeled it with question marks.\n\n\n\n\nlibrary(knitr) \n\nlda30_df <- as_tibble(terms(lda_fits[[2]]))\n\nnames(lda30_df) <- \n  c(\"01_Lost_Sheep\",\n    \"02_Jesus_Christ_Savior\", \n    \"03_Priesthood_Leaders_Responsibility\",\n    \"04_Spiritual_Light_of_the_World\",\n    \"05_Gospel_Scripture_Study\",\n    \"06_Sins_Repentace_Atonement\", \n    \"07_Lords_People_Zion??\",\n    \"08_Missionary_Service\",\n    \"09_Joseph_Smith\",\n    \"10_Church_Welfare_Fast_Offerings\",\n    \"11_???\",\n    \"12_Book_of_Mormon_Scripture_Reading\",\n    \"13_???\",\n    \"14_Priesthood_Power_Keys\",\n    \"15_Sustain_Church_Officers\",\n    \"16_Holy_Ghost_Testimony\",\n    \"17_Love_of_God_Jesus_Christ\",\n    \"18_Prayer\",\n    \"19_Time_to_Choose_Eternal_Life\",\n    \"20_Relief_Society\",\n    \"21_Sacrament_Sabbath_Day\",\n    \"22_Temple_Covenants_Blessings\",\n    \"23_Gods_Plan_Eternal_Life\",\n    \"24_???\",\n    \"25_Morals_Standards??\",\n    \"26_Faith_in_Jesus_Christ\",\n    \"27_??\", \n    \"28_Prophet_President\",\n    \"29_???\",\n    \"30_Family_Home\"\n    )\n\nkable(lda30_df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01_Lost_Sheep\n02_Jesus_Christ_Savior\n03_Priesthood_Leaders_Responsibility\n04_Spiritual_Light_of_the_World\n05_Gospel_Scripture_Study\n06_Sins_Repentace_Atonement\n07_Lords_People_Zion??\n08_Missionary_Service\n09_Joseph_Smith\n10_Church_Welfare_Fast_Offerings\n11_???\n12_Book_of_Mormon_Scripture_Reading\n13_???\n14_Priesthood_Power_Keys\n15_Sustain_Church_Officers\n16_Holy_Ghost_Testimony\n17_Love_of_God_Jesus_Christ\n18_Prayer\n19_Time_to_Choose_Eternal_Life\n20_Relief_Society\n21_Sacrament_Sabbath_Day\n22_Temple_Covenants_Blessings\n23_Gods_Plan_Eternal_Life\n24_???\n25_Morals_Standards??\n26_Faith_in_Jesus_Christ\n27_??\n28_Prophet_President\n29_???\n30_Family_Home\n\n\n\n\nsheep\njesus\nchurch\nlight\ngospel\nrepentance\nlord\nmission\njoseph\nwelfare\nalma\nbook\nbrother\npriesthood\nmanifest\nholy\nlove\nfather\nlife\nwomen\nsacrament\ntemple\ngod\nchurch\ngod\nfaith\ntime\npresident\nlord\nchildren\n\n\nwater\nchrist\npriesthood\npeace\nchurch\nsins\ngod\nmissionaries\nsmith\nchurch\nne\nmormon\nhome\nchurch\npresidency\nspirit\nchrist\nprayer\ntime\nsociety\nday\ncovenants\neternal\npeople\nevil\nchrist\ndon’t\nlord\nthy\nfamily\n\n\nking\nson\nbishop\nworld\nlearn\nchrist\npeople\nmissionary\nchurch\npoor\ngod\nread\nmother\npower\nsustain\nghost\njesus\nheavenly\npath\nrelief\nremember\nblessings\nlife\nlord\nworld\njesus\nday\nchurch\nthou\nhome\n\n\ngod\nfather\nquorum\nchrist\nteach\natonement\nworld\ngospel\nprophet\nservices\nmosiah\nchrist\nhand\nauthority\npresident\ngod\nchurch\ngod\nhappiness\nsisters\nsabbath\ncovenant\nfather\nconference\nlife\ngod\nlife\nprophet\nye\nparents\n\n\nlost\ngod\nstake\ndarkness\nprinciples\njesus\nearth\nserve\ngod\nlord\nlord\nscriptures\npresident\nbrethren\nfavor\nlord\nsavior\npray\nhope\nwoman\nsacrifice\nordinances\nplan\nworld\npeople\nlord\nboy\ngod\ngod\nfamilies\n\n\nlord\njohn\nward\nspiritual\ntaught\nsin\nday\nchurch\nchrist\ntithing\njesus\njesus\nlife\naaronic\ntwelve\ntestimony\ngod\nlove\nlives\nsister\ntime\nfamily\nearth\nsaints\nmoral\ntestimony\nhome\nconference\nthee\nlove\n\n\nlife\nlife\npresident\nlife\nstudy\nrepent\nland\nlord\njesus\nfast\nye\ngod\nwords\nkeys\nproposed\nchrist\nday\nlord\neternal\ndaughters\nsunday\nlord\nchrist\ntemple\nlord\npower\ntold\nkimball\nshalt\nmarriage\n\n\ndavid\ndeath\nleaders\ntime\nspiritual\nsavior\nzion\ntime\ngospel\npeople\npatience\nwords\nday\nhold\nquorum\nreceive\nlife\nfeel\nchoose\nchurch\nmeeting\nsacred\nworld\nbuilding\nsatan\nlives\nschool\nprophets\ncommandments\nmother\n\n\nshepherd\nworld\nhome\ngospel\nscriptures\nmercy\nnations\nservice\nday\nfamily\npeople\nnephi\nfound\ngod\nchurch\ngift\ngospel\nson\nlord\npresident\nmusic\nreceive\njesus\nday\nstandards\nlife\nfather\nhinckley\nmatt\nfather\n\n\ntime\nsavior\nresponsibility\ntruth\ndoctrine\ngod\ntime\nelder\nearth\nfood\nheart\nword\nago\nlord\ncounselor\npower\nsisters\nheart\nfollow\nworld\nsacred\ntemples\nlord\nsisters\nlive\ngospel\nlove\ncalled\nwords\nwife\n\n\n\n\n\n\nlda32_df <- as_tibble(terms(lda_fits[[1]]))\n\nnames(lda32_df) <- \n  c(\"01_Sustain_Church_Officers\",\n    \"02_Repentence\",\n    \"03_Church_Audit_Financial\",\n    \"04_Gospel_Scripture_Study\",\n    \"05_Jesus_Christ_Resurrection\",\n    \"06_Spiritual_Light_of_the_World\",\n    \"07_???\",\n    \"08_???\",\n    \"09_Prophet_President\",\n    \"10_Tithing\",\n    \"11_Standards_Against_Evil??\",\n    \"12_Priesthood_Power_Keys\",\n    \"13_Conference???\",\n    \"14_Book_of_Mormon_Joseph_Smith\",\n    \"15_Holy_Ghost_Prayer_Testimony\",\n    \"16_Marriage_Family\",\n    \"17_Church_Leaders\",\n    \"18_Church_Welfare_Fast_Offerings\",\n    \"19_Gods_Plan_Eternal_Life\",\n    \"20_Covenants\",\n    \"21_Joy_Suffering_Faith\",\n    \"22_Tree_of_Life_Path???\",\n    \"23_Missionary_Service\",\n    \"24_Church_of_Jesus_Christ\",\n    \"25_Faith_in_Jesus_Christ\",\n    \"26_Temple_Ordinances\",\n    \"27_Lords_People???\",\n    \"28_Love_Jesus_Christ\",  \n    \"29_???\", # I think this is my garbage topic\n    \"30_Relief_Society_Women\",\n    \"31_Family_Home\",\n    \"32_???\" # I think this is a garbage topic too\n    )\n\nkable(lda32_df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01_Sustain_Church_Officers\n02_Repentence\n03_Church_Audit_Financial\n04_Gospel_Scripture_Study\n05_Jesus_Christ_Resurrection\n06_Spiritual_Light_of_the_World\n07_???\n08_???\n09_Prophet_President\n10_Tithing\n11_Standards_Against_Evil??\n12_Priesthood_Power_Keys\n13_Conference???\n14_Book_of_Mormon_Joseph_Smith\n15_Holy_Ghost_Prayer_Testimony\n16_Marriage_Family\n17_Church_Leaders\n18_Church_Welfare_Fast_Offerings\n19_Gods_Plan_Eternal_Life\n20_Covenants\n21_Joy_Suffering_Faith\n22_Tree_of_Life_Path???\n23_Missionary_Service\n24_Church_of_Jesus_Christ\n25_Faith_in_Jesus_Christ\n26_Temple_Ordinances\n27_Lords_People???\n28_Love_Jesus_Christ\n29_???\n30_Relief_Society_Women\n31_Family_Home\n32_???\n\n\n\n\nmanifest\nalma\nchurch\ngospel\njesus\nlight\nking\nbrother\npresident\nlord\nevil\npriesthood\nchurch\nbook\nholy\nmarriage\nchurch\nwelfare\nlife\ncovenants\nlife\nlife\nmission\nchurch\nfaith\ntemple\nlord\nlove\ntime\nwomen\nchildren\nthou\n\n\npresidency\nsins\nprogram\nscriptures\ngod\ndarkness\nlord\nhome\nchurch\ntithing\nworld\npower\npeople\nmormon\nspirit\nlove\nbishop\nchurch\ngod\ncovenant\njoy\nwater\nmissionaries\nchrist\nchrist\nfamily\npeople\nchrist\ndon’t\nsociety\nfamily\nthy\n\n\nsustain\nrepentance\ndepartment\nlearn\nchrist\nne\ngod\nmother\nprophet\npay\npeople\nlord\nconference\njoseph\nghost\nwife\nquorum\npoor\neternal\nlord\nsuffering\njourney\nmissionary\njesus\npeace\ntemples\ngod\njesus\nlife\nrelief\nhome\nlord\n\n\npresident\nchrist\nauditing\nstudy\nfather\ngod\ncourage\nhand\nlord\nsacrifice\ngod\nbrethren\nsaints\nsmith\nlord\ngod\nward\nservices\nplan\nsacrament\nlord\npath\nchurch\ngod\nhope\nordinances\nearth\ngod\nday\nsisters\nparents\nye\n\n\nfavor\ngod\nmembership\nspiritual\nlife\njesus\nisrael\nfather\ngod\nmoney\nstandards\ngod\nsalt\nprophet\nfather\nlife\nstake\nfast\ncommandments\nday\njesus\ntree\nserve\ngospel\njesus\nlord\nworld\nsavior\nfather\nwoman\nfather\ngod\n\n\nproposed\nsin\nfunds\nteach\nson\nspiritual\ndavid\nwords\njoseph\nday\nmoral\nauthority\ncity\nread\ngod\nchildren\nhome\nprogram\nhappiness\nholy\ngod\nchrist\ngospel\nworld\nlord\nhouse\nday\nfather\ndidn’t\nsister\nfamilies\nthee\n\n\nquorum\nrepent\neducation\ntaught\ndeath\nworld\nstand\nago\nconference\nblessings\nsatan\naaronic\nlake\nchrist\nprayer\nfamily\npresident\npeople\nfather\nblessings\nfaith\ntime\nservice\nday\ngod\nblessings\nland\nsisters\nschool\nchurch\nlove\njesus\n\n\ntwelve\nye\ncouncil\nword\nworld\ntime\ndaniel\nday\nsmith\ntime\nyouth\nkeys\nlord\ngod\npray\nhusband\nleaders\nprinciples\nchoose\nchrist\npain\njesus\ntime\ntruth\npower\nsacred\ntime\nheavenly\nboy\npresident\nteach\nshalt\n\n\ncounselor\njesus\nfinancial\nchrist\nresurrection\nchrist\npeople\npresident\nkimball\npeople\nlife\nhold\nday\njesus\nwords\neternal\npriesthood\nfood\nheavenly\nsacred\nhealing\nfollow\nlord\nearth\nlife\ndead\nnations\nfeel\nremember\ndaughters\nmother\nmatt\n\n\nchurch\natonement\npercent\nprinciples\nearth\ntruth\nhand\nlife\nprophets\nlife\nclean\nduty\nworld\nlord\ntestimony\nwoman\nteachers\nfamily\ngod’s\nremember\ntrials\nday\nelder\ntrue\nlives\ntime\ndays\nheart\nfriends\nmother\nchild\nlove\n\n\n\n\n\n\n\nBattle: 30-topic vs 32-topic\nTo wrap my mind around the pros and cons of the two models. I captured some of the differences in this table.\n\nThis is where contextual knowledge of the data is needed.\n\n\n\n\n\n\n\n\n30-Topic Model\n32-Topic Model\n\n\n\n\nBook of Mormon gets paired with scriptures and scripture reading. Joseph Smith has his own topic.\nBook of Mormon gets paired with joseph smith\n\n\nPrayer has its own topic.\nprayer gets placed inside the The Holy Ghost and Testimony topic.\n\n\nJesus Christ is paired with savior\nJesus Christ is paired with resurrection.\n\n\nSeems to have a Lost Sheep topic.\nThere is not topic that contains sheep.\n\n\nsacrament is paired with sabbath day (topic #21)\nsacrament is paired with covenants.\n\n\ntithing is found under the Church Welfare topic.\ntithing is paired with sacrifice and pay, which seems to solidly form a Tithing topic\n\n\n\nI like the fact that Joseph Smith has his own topic in the 30-topic model; and, it probably makes more sense to bundle the Book of Mormon with scriptures (since it is part of the scriptural canon of The Church of Jesus Christ of Latter-day Saints) than it does with Joseph Smith (who translated it). A strong nudge to favor the 30-topic model.\nPrayer and Christ’s direction to find and feed His “lost sheep” are both very common topics in GC talks. The 30-topic has separate topics for each of these. That’s a couple of votes for the 30-topic model.\nI especially like that the Jesus Christ topic contains savior. I prefer that associate as Savior over the associate with resurrection in the 32-topic model. I view His resurrection as part of His saving.\nMembers of the Church meet together on Sundays (the Sabbath day) to partake of the Sacrament (i.e., the Lord’s Supper), so it’s very appropriate to associate the Sacrament with the Sabbath day. However, the Sacrament is a time for church members to remember the covenants they made at baptism; so it’s equally appropriate to associate the Sacrament with covenants as well. So, this point is a wash.\nTithing as its own topic (in the 32-topic model) is appealing. A win for the 32-topic model. However, tithing is often spoken of in the context of fast offerings. Fast offerings are free-will monetary offerings given in conjunction with a fast – the money saved from skipping meals during the fast is donated to help the poor and needy. A counter for the 30-topic model. But the 32-topic option highlights tithing in terms of sacrifice. You might consider tithing as a baseline measure of an individual’s willingness to sacrifice for the Lord. A stronger counter for the 32-topic model.\nSo, overall, we’ll go with the 30-topic model.\n\nAs I explored models with more topics, I discovered that other topics crystalized, examples include youth and the latter days, home teaching (a program to ensure members of the church are taken care of and watched over), pioneers and trek to Salt Lake City, and revelation.\n\nLet’s pull out the 30-topic model.\n\nlda30_fit <- lda_fits[[2]]"
  },
  {
    "objectID": "blog/nlp/gc_topic_model_best_fit.html#interpretting-the-topics",
    "href": "blog/nlp/gc_topic_model_best_fit.html#interpretting-the-topics",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Interpretting the topics",
    "text": "Interpretting the topics\nMaximal divergence does not necessarily mean that that number of topics is maximally meaningful. So I took the models with the top three divergence scores (32-topics, 30-topics, and 28 topics) and explored the quality of the topics.\nI created these models in parallel on my server. Here’s the code:\n\nn <- c(32, 30, 28)\n\nplan(multisession, workers = 3)\nlda_fits <- n %>% \n  future_map(\n    ~textmodel_lda(unigram_dfm, k = .x),\n    furrr_options(seed = TRUE))\n\nI created labels for each topic based on the words that the topic was composed of to evaluate the topic quality. Here I’ll demonstrate the 28-topic model.\nI extracted the words per topic with the terms() function.\n\n\n\n\nlibrary(seededlda)\nas_tibble(terms(lda_fits[[1]]))\n\n# A tibble: 10 × 32\n   topic1     topic2    topic3 topic4 topic5 topic6 topic7 topic8 topic9 topic10\n   <chr>      <chr>     <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  \n 1 manifest   alma      church gospel jesus  light  king   broth… presi… lord   \n 2 presidency sins      progr… scrip… god    darkn… lord   home   church tithing\n 3 sustain    repentan… depar… learn  christ ne     god    mother proph… pay    \n 4 president  christ    audit… study  father god    coura… hand   lord   sacrif…\n 5 favor      god       membe… spiri… life   jesus  israel father god    money  \n 6 proposed   sin       funds  teach  son    spiri… david  words  joseph day    \n 7 quorum     repent    educa… taught death  world  stand  ago    confe… blessi…\n 8 twelve     ye        counc… word   world  time   daniel day    smith  time   \n 9 counselor  jesus     finan… christ resur… christ people presi… kimba… people \n10 church     atonement perce… princ… earth  truth  hand   life   proph… life   \n# … with 22 more variables: topic11 <chr>, topic12 <chr>, topic13 <chr>,\n#   topic14 <chr>, topic15 <chr>, topic16 <chr>, topic17 <chr>, topic18 <chr>,\n#   topic19 <chr>, topic20 <chr>, topic21 <chr>, topic22 <chr>, topic23 <chr>,\n#   topic24 <chr>, topic25 <chr>, topic26 <chr>, topic27 <chr>, topic28 <chr>,\n#   topic29 <chr>, topic30 <chr>, topic31 <chr>, topic32 <chr>"
  },
  {
    "objectID": "blog/nlp/gc_topic_model_best_fit.html",
    "href": "blog/nlp/gc_topic_model_best_fit.html",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "",
    "text": "Semi-annually, members of The Church of Jesus Christ of Latter-day Saints gather across the world for General Conference (GC) to hear messages and talks about the gospel of Jesus Christ. These messages are delivered by prophets, apostles, and other leaders in the Church. GC occurs the first weekend of April and October. Although general conferences have occurred since the founding of the Church in 1830, [talks (and their text)] since 1971 are available on the Church’s website(https://www.churchofjesuschrist.org/study/general-conference).\nGC is one of my favorite times of the year! Seriously! For me, it competes with Christmas.\nNaturally, I’m curious about the topics that are taught at GC. I wanted to apply NLP topic modeling to GC."
  },
  {
    "objectID": "blog/nlp/gc_topic_model_best_fit.html#about-the-data",
    "href": "blog/nlp/gc_topic_model_best_fit.html#about-the-data",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "About the data",
    "text": "About the data\nI was able to scrape the data from the GC website.\nEvery semi-annual conference has 4-5 sessions. Each session contains a series of talks. There are approximately 36-40 talks across all sessions in a conference. Every talk will be a document in topic modeling. Since I have the GC dates, I can study the topics longitudinally. I’m specifically curious about how the frequency of different topics has changed over the decades.\nI start simple and only deal with unigrams."
  },
  {
    "objectID": "blog/nlp/gc_topic_model_best_fit.html#objective",
    "href": "blog/nlp/gc_topic_model_best_fit.html#objective",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Objective",
    "text": "Objective\nMy objective in this post is to fit a topic model to the GC corpus. Therefore, I need to find the number of topics that best fits the data.\nThe approach is very similar to clustering – another unsupervised algorithm. I’ll fit topic models using a range of different numbers of topics (20-topic model, 22-topic model,…,n-topic). Then calculate the divergence of each model and find the model with the maximum divergence.\n\nPerplexity is also a common metric used to explore the optimal number of topics. I use divergence because it is implemented in the seededlda package.\n\nI’ll then qualitatively assess a smaller range of models near the optimal divergence range.\nThis post will demonstrate the beginning of this iterative quantitative-qualitative process to finding the optimal number of topics."
  },
  {
    "objectID": "blog/nlp/gc_topic_model_best_fit.html#interpreting-the-topics-the-qualitative-part",
    "href": "blog/nlp/gc_topic_model_best_fit.html#interpreting-the-topics-the-qualitative-part",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Interpreting the topics – the qualitative part",
    "text": "Interpreting the topics – the qualitative part\nMaximal divergence does not necessarily mean that that number of topics is maximally meaningful. So I took the models with the top three divergence scores (32-topics, 30-topics, and 28 topics) and explored the quality of the topics.\nI created these models in parallel on my server. Here’s the code:\n\nn <- c(28, 30, 32)\n\nplan(multisession, workers = 3)\nlda_fits <- n %>% \n  future_map(\n    ~textmodel_lda(unigram_dfm, k = .x),\n    furrr_options(seed = TRUE))\n\nI created labels for each topic based on the words that the topic was composed of to evaluate the topic quality. Here I’ll demonstrate this process with the 30- and 32-topic models.\nI extracted the words per topic with the terms() function and formed them into a tibble for ease of reading. Then I proceeded to subjectively interpret the topics based on the top-10 words in each topic. I don’t believe there is a way to avoid this. Notice that I update the column names with the meaningful labels.\nIt is expected that there will be some noisy topics. If the topic wasn’t clear to me, I labeled it with question marks.\n\n\n\n\nlda30_df <- as_tibble(terms(lda_fits[[2]]))\n\nnames(lda30_df) <- \n  c(\"01_Lost_Sheep\",\n    \"02_Jesus_Christ_Savior\", \n    \"03_Priesthood_Leaders_Responsibility\",\n    \"04_Spiritual_Light_of_the_World\",\n    \"05_Gospel_Scripture_Study\",\n    \"06_Sins_Repentace_Atonement\", \n    \"07_Lords_People_Zion??\",\n    \"08_Missionary_Service\",\n    \"09_Joseph_Smith\",\n    \"10_Church_Welfare_Fast_Offerings\",\n    \"11_???\",\n    \"12_Book_of_Mormon_Scripture_Reading\",\n    \"13_???\",\n    \"14_Priesthood_Power_Keys\",\n    \"15_Sustain_Church_Officers\",\n    \"16_Holy_Ghost_Testimony\",\n    \"17_Love_of_God_Jesus_Christ\",\n    \"18_Prayer\",\n    \"19_Time_to_Choose_Eternal_Life\",\n    \"20_Relief_Society\",\n    \"21_Sacrament_Sabbath_Day\",\n    \"22_Temple_Covenants_Blessings\",\n    \"23_Gods_Plan_Eternal_Life\",\n    \"24_???\",\n    \"25_Morals_Standards??\",\n    \"26_Faith_in_Jesus_Christ\",\n    \"27_??\", \n    \"28_Prophet_President\",\n    \"29_???\",\n    \"30_Family_Home\"\n    )\n\nlda30_df\n\n# A tibble: 10 × 30\n   01_Lost_She…¹ 02_Je…² 03_Pr…³ 04_Sp…⁴ 05_Go…⁵ 06_Si…⁶ 07_Lo…⁷ 08_Mi…⁸ 09_Jo…⁹\n   <chr>         <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 sheep         jesus   church  light   gospel  repent… lord    mission joseph \n 2 water         christ  priest… peace   church  sins    god     missio… smith  \n 3 king          son     bishop  world   learn   christ  people  missio… church \n 4 god           father  quorum  christ  teach   atonem… world   gospel  prophet\n 5 lost          god     stake   darkne… princi… jesus   earth   serve   god    \n 6 lord          john    ward    spirit… taught  sin     day     church  christ \n 7 life          life    presid… life    study   repent  land    lord    jesus  \n 8 david         death   leaders time    spirit… savior  zion    time    gospel \n 9 shepherd      world   home    gospel  script… mercy   nations service day    \n10 time          savior  respon… truth   doctri… god     time    elder   earth  \n# … with 21 more variables: `10_Church_Welfare_Fast_Offerings` <chr>,\n#   `11_???` <chr>, `12_Book_of_Mormon_Scripture_Reading` <chr>,\n#   `13_???` <chr>, `14_Priesthood_Power_Keys` <chr>,\n#   `15_Sustain_Church_Officers` <chr>, `16_Holy_Ghost_Testimony` <chr>,\n#   `17_Love_of_God_Jesus_Christ` <chr>, `18_Prayer` <chr>,\n#   `19_Time_to_Choose_Eternal_Life` <chr>, `20_Relief_Society` <chr>,\n#   `21_Sacrament_Sabbath_Day` <chr>, `22_Temple_Covenants_Blessings` <chr>, …\n\n\n\nlda32_df <- as_tibble(terms(lda_fits[[1]]))\n\nnames(lda32_df) <- \n  c(\"01_Sustain_Church_Officers\",\n    \"02_Repentence\",\n    \"03_Church_Audit_Financial\",\n    \"04_Gospel_Scripture_Study\",\n    \"05_Jesus_Christ_Resurrection\",\n    \"06_Spiritual_Light_of_the_World\",\n    \"07_???\",\n    \"08_???\",\n    \"09_Prophet_President\",\n    \"10_Tithing\",\n    \"11_Standards_Against_Evil??\",\n    \"12_Priesthood_Power_Keys\",\n    \"13_Conference???\",\n    \"14_Book_of_Mormon_Joseph_Smith\",\n    \"15_Holy_Ghost_Prayer_Testimony\",\n    \"16_Marriage_Family\",\n    \"17_Church_Leaders\",\n    \"18_Church_Welfare_Fast_Offerings\",\n    \"19_Gods_Plan_Eternal_Life\",\n    \"20_Covenants\",\n    \"21_Joy_Suffering_Faith\",\n    \"22_Tree_of_Life_Path???\",\n    \"23_Missionary_Service\",\n    \"24_Church_of_Jesus_Christ\",\n    \"25_Faith_in_Jesus_Christ\",\n    \"26_Temple_Ordinances\",\n    \"27_Lords_People???\",\n    \"28_Love_Jesus_Christ\",  \n    \"29_???\", # I think this is my garbage topic\n    \"30_Relief_Society_Women\",\n    \"31_Family_Home\",\n    \"32_???\" # I think this is a garbage topic too\n    )\n\nlda32_df\n\n# A tibble: 10 × 32\n   01_Sustain_…¹ 02_Re…² 03_Ch…³ 04_Go…⁴ 05_Je…⁵ 06_Sp…⁶ 07_??…⁷ 08_??…⁸ 09_Pr…⁹\n   <chr>         <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 manifest      alma    church  gospel  jesus   light   king    brother presid…\n 2 presidency    sins    program script… god     darkne… lord    home    church \n 3 sustain       repent… depart… learn   christ  ne      god     mother  prophet\n 4 president     christ  auditi… study   father  god     courage hand    lord   \n 5 favor         god     member… spirit… life    jesus   israel  father  god    \n 6 proposed      sin     funds   teach   son     spirit… david   words   joseph \n 7 quorum        repent  educat… taught  death   world   stand   ago     confer…\n 8 twelve        ye      council word    world   time    daniel  day     smith  \n 9 counselor     jesus   financ… christ  resurr… christ  people  presid… kimball\n10 church        atonem… percent princi… earth   truth   hand    life    prophe…\n# … with 23 more variables: `10_Tithing` <chr>,\n#   `11_Standards_Against_Evil??` <chr>, `12_Priesthood_Power_Keys` <chr>,\n#   `13_Conference???` <chr>, `14_Book_of_Mormon_Joseph_Smith` <chr>,\n#   `15_Holy_Ghost_Prayer_Testimony` <chr>, `16_Marriage_Family` <chr>,\n#   `17_Church_Leaders` <chr>, `18_Church_Welfare_Fast_Offerings` <chr>,\n#   `19_Gods_Plan_Eternal_Life` <chr>, `20_Covenants` <chr>,\n#   `21_Joy_Suffering_Faith` <chr>, `22_Tree_of_Life_Path???` <chr>, …\n\n\nTo wrap my mind around the pros and cons of the two models. I captured some of the differences in this table.\n\n\n\n\n\n\n\n30-Topic Model\n32-Topic Model\n\n\n\n\nBook of Mormon gets paired with scriptures and scripture reading. Joseph Smith has his own topic.\nBook of Mormon gets paired with joseph smith\n\n\nPrayer has its own topic.\nprayer gets placed inside the The Holy Ghost and Testimony topic.\n\n\nJesus Christ is paired with savior\nJesus Christ is paired with resurrection.\n\n\nSeems to have a Lost Sheep topic.\nThere is not topic that contains sheep.\n\n\nsacrament is paired with sabbath day (topic #21)\nsacrament is paired with covenants.\n\n\ntithing is found under the Church Welfare topic.\ntithing is paired with sacrifice and pay, which seems to solidly form a Tithing topic\n\n\n\nI like the fact that Joseph Smith has his own topic in the 30-topic model; and, it probably makes more sense to bundle the Book of Mormon with scriptures (since it is part of the scriptural canon of The Church of Jesus Christ of Latter-day Saints) than it does with Joseph Smith (who translated it). A strong nudge to favor the 30-topic model.\nPrayer and and Christ’s direction to find and feed His “lost sheep” are both very common topics in GC talks. That’s a couple votes for the 30-topic model.\nI especially like that the Jesus Christ topic contains savior. I prefer that associat as Savior over the associate with resurrection in the 32-topic model. I view His resurrection as part of His saving.\nMembers of the Church meet together on Sundays (the Sabbath day) to partake of the Sacrament (i.e., the Lord’s Supper), so it’s very appropriate to associate the Sacrament with the Sabbath day. However, the Sacrament is a time for church members to remember the covenants they made at baptism; so it’s equally appropriate to associate the Sacrament with covenants as well. So, this point is a wash.\nTithing as its own topic (in the 32-topic model) is appealing. A win for the 32-topic model. However, tithing is often spoken of in the context of fast offerings. Fast offerings are free will monetary offerings given in conjunction with a fast – the money saved from skipping meals during the fast is donated to help the poor and needy. A counter for the 30-topic model. But the 32-topic option highlights tithing in terms of sacrifice. You might consider tithing as a baseline measure of an individual’s willingness to sacrifice for the Lord. A stronger counter for the 32-topic model.\nSo, we’ll go with the 30-topic model.\n\nlda30_fit <- lda_fits[[2]]"
  },
  {
    "objectID": "blog/nlp/gc_topic_model_best_fit.html#exploring-results",
    "href": "blog/nlp/gc_topic_model_best_fit.html#exploring-results",
    "title": "seededlda Topic Model - Finding the best fit",
    "section": "Exploring results",
    "text": "Exploring results\nNow that we have a finalized topic model, let’s look at the results.\nFirst, I’ll use the LDA model to predict the topic of each of the talks. To do this, I’ll use topics(lda30_fit). That returns a named list, like this:\n\nhead(topics(lda30_fit))\n\n       1971_04_a_witness_and_a_blessing 1971_04_all_may_share_in_adams_blessing \n                                 topic9                                 topic22 \n               1971_04_be_slow_to_anger             1971_04_choose_you_this_day \n                                 topic4                                  topic7 \n        1971_04_drink_of_the_pure_water   1971_04_eternal_joy_is_eternal_growth \n                                topic26                                 topic23 \n30 Levels: topic1 topic2 topic3 topic4 topic5 topic6 topic7 topic8 ... topic30\n\n\nSo, I assemble a data frame with the doc_ids and the topic_ids.\n\nlibrary(lubridate)\n\n# assemble doc_ids and topics\ntalk_topics_df <- \n  tibble(\n    doc_id = names(topics(lda30_fit)),\n    topic_id = topics(lda30_fit)) %>% \n  mutate(conf_date = str_sub(doc_id, 1, 7) %>% \n           str_replace(\"_\", \"-\") %>%  ym())\n\nSince the topic_ids are not very helpful, I’ll combine them with the topic labels I created above and join them into the talk data frame.\n\n# create a topic label map, to get more meaningful labels\ntopic_df <- tibble(\n  topic_id = str_c(\"topic\", 1:30),\n  topic_label = str_sub(names(lda30_df), 4))\n\n# join topic labels in\ntalk_topics_df <- \n  talk_topics_df %>% left_join(topic_df)\n\nI’d like to explore the number of talks at each conference over time, so I’ll aggregate the topic counts for each conference.\n\n# get topic counts in each conference\nconf_topic_counts_df <- \n  talk_topics_df %>% \n  count(conf_date, topic_label)\n\nNow, we are ready to plot. I did quite a bit of exploration and came across this plot. I found it interesting that the “Love_of_God_Jesus_Christ” topic has become more prevalent since about 2010.\n\nconf_topic_counts_df %>% \n  filter(topic_label == \"Love_of_God_Jesus_Christ\") %>% \n  ggplot(aes(x=conf_date, y=n)) +\n  geom_col(fill = \"purple\") +\n  theme(legend.position = \"none\")\n\n\n\n\nHere is a list of the top 20 words in the Love_of_God_Jesus_Christ topic (it was topic 17).\n\nterms(lda30_fit, 20)[, 17]\n\n [1] \"love\"     \"christ\"   \"jesus\"    \"church\"   \"savior\"   \"god\"     \n [7] \"day\"      \"life\"     \"gospel\"   \"sisters\"  \"brothers\" \"people\"  \n[13] \"lives\"    \"heart\"    \"serve\"    \"service\"  \"world\"    \"children\"\n[19] \"follow\"   \"feel\""
  },
  {
    "objectID": "blog/dataprep/test.html",
    "href": "blog/dataprep/test.html",
    "title": "test",
    "section": "",
    "text": "Test\n\n1 + 1\n\n[1] 2"
  }
]